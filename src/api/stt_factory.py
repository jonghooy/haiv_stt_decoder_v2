#!/usr/bin/env python3
"""
STT Service Factory
ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ STT ì„œë¹„ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ í´ë˜ìŠ¤
"""

import logging
from typing import Dict, Any, Optional

from .base_stt_service import BaseSTTService
from .whisper_stt_adapter import WhisperSTTServiceAdapter

logger = logging.getLogger(__name__)

# NeMo ì§€ì› í™•ì¸
try:
    from .nemo_stt_service import NeMoSTTService, NEMO_AVAILABLE
except ImportError:
    NEMO_AVAILABLE = False
    logger.warning("âš ï¸ NeMo STT ì„œë¹„ìŠ¤ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

# ì§€ì›ë˜ëŠ” ëª¨ë¸ íƒ€ì…ê³¼ ì´ë¦„ë“¤
SUPPORTED_MODELS = {
    "whisper": {
        "models": ["tiny", "base", "small", "medium", "large-v1", "large-v2", "large-v3"],
        "default": "large-v3",
        "description": "OpenAI Whisper ëª¨ë¸ (Faster Whisper êµ¬í˜„)"
    },
    "nemo": {
        "models": [
            "./FastConformer-Transducer-BPE_9.75.nemo",
            "./FastConformer-Transducer-BPE_6.00.nemo",
            "eesungkim/stt_kr_conformer_transducer_large",
            "eesungkim/korean-stt-model",
            "nvidia/stt_ko_conformer_ctc_large",
            "nvidia/stt_ko_conformer_transducer_large",
            "nvidia/stt_en_conformer_ctc_large",
            "nvidia/stt_en_conformer_transducer_large"
        ],
        "default": "./FastConformer-Transducer-BPE_9.75.nemo",
        "description": "NVIDIA NeMo ASR ëª¨ë¸ (ë¡œì»¬ ì»¤ìŠ¤í…€ ëª¨ë¸ í¬í•¨)",
        "available": NEMO_AVAILABLE
    }
}


class STTServiceFactory:
    """STT ì„œë¹„ìŠ¤ ìƒì„± íŒ©í† ë¦¬"""
    
    @staticmethod
    def create_service(model_type: str, model_name: str, device: str = "cuda", **kwargs) -> BaseSTTService:
        """ëª¨ë¸ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ STT ì„œë¹„ìŠ¤ ìƒì„±"""
        model_type = model_type.lower()
        
        logger.info(f"ğŸ­ STT ì„œë¹„ìŠ¤ ìƒì„±: {model_type} - {model_name}")
        
        if model_type == "whisper":
            return WhisperSTTServiceAdapter(
                model_name=model_name,
                device=device,
                compute_type=kwargs.get("compute_type", "float16"),
                **{k: v for k, v in kwargs.items() if k != "compute_type"}
            )
        elif model_type == "nemo":
            if not NEMO_AVAILABLE:
                raise ValueError(
                    "NeMo íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                    "'pip install nemo-toolkit[asr] omegaconf hydra-core'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”"
                )
            return NeMoSTTService(
                model_name=model_name,
                device=device,
                **kwargs
            )
        else:
            supported_types = [k for k, v in SUPPORTED_MODELS.items() if v.get("available", True)]
            raise ValueError(
                f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}. "
                f"ì§€ì› ëª¨ë¸: {supported_types}"
            )
    
    @staticmethod
    def get_supported_models() -> Dict[str, Any]:
        """ì§€ì›ë˜ëŠ” ëª¨ë¸ ëª©ë¡ ë°˜í™˜"""
        return SUPPORTED_MODELS
    
    @staticmethod
    def validate_model(model_type: str, model_name: Optional[str] = None) -> bool:
        """ëª¨ë¸ íƒ€ì…ê³¼ ì´ë¦„ ìœ íš¨ì„± ê²€ì¦"""
        model_type = model_type.lower()
        
        # ëª¨ë¸ íƒ€ì… í™•ì¸
        if model_type not in SUPPORTED_MODELS:
            return False
        
        model_info = SUPPORTED_MODELS[model_type]
        
        # ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
        if not model_info.get("available", True):
            return False
        
        # ëª¨ë¸ ì´ë¦„ í™•ì¸ (ì œê³µëœ ê²½ìš°)
        if model_name and model_name not in model_info["models"]:
            # ì—„ê²©í•œ ê²€ì¦ì„ í•˜ì§€ ì•ŠìŒ (ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ í—ˆìš©)
            logger.warning(f"âš ï¸ ëª¨ë¸ {model_name}ì€ ê³µì‹ ì§€ì› ëª©ë¡ì— ì—†ìŠµë‹ˆë‹¤")
        
        return True
    
    @staticmethod
    def get_default_model(model_type: str) -> str:
        """ëª¨ë¸ íƒ€ì…ì˜ ê¸°ë³¸ ëª¨ë¸ ì´ë¦„ ë°˜í™˜"""
        model_type = model_type.lower()
        
        if model_type in SUPPORTED_MODELS:
            return SUPPORTED_MODELS[model_type]["default"]
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ íƒ€ì…: {model_type}")
    
    @staticmethod
    def get_model_description(model_type: str) -> str:
        """ëª¨ë¸ íƒ€ì… ì„¤ëª… ë°˜í™˜"""
        model_type = model_type.lower()
        
        if model_type in SUPPORTED_MODELS:
            return SUPPORTED_MODELS[model_type]["description"]
        else:
            return f"ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë¸ íƒ€ì…: {model_type}"
    
    @staticmethod
    def is_nemo_available() -> bool:
        """NeMo ì§€ì› ì—¬ë¶€ í™•ì¸"""
        return NEMO_AVAILABLE
    
    @staticmethod
    def get_available_model_types() -> list:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ íƒ€ì… ëª©ë¡ ë°˜í™˜ (ì„¤ì¹˜ ì—¬ë¶€ì™€ ê´€ê³„ì—†ì´ ëª¨ë“  íƒ€ì… ë°˜í™˜)"""
        return list(SUPPORTED_MODELS.keys())
    
    @staticmethod
    def get_usable_model_types() -> list:
        """ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ íƒ€ì… ëª©ë¡ ë°˜í™˜ (ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸)"""
        return [
            model_type for model_type, info in SUPPORTED_MODELS.items()
            if info.get("available", True)
        ] 