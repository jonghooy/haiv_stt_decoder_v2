#!/usr/bin/env python3
"""
NeMo STT Service
NVIDIA NeMo ASR ëª¨ë¸ì„ ì‚¬ìš©í•œ STT ì„œë¹„ìŠ¤
"""

import asyncio
import logging
import time
from typing import Dict, Any, Optional, List
import numpy as np
import torch

from .base_stt_service import BaseSTTService
from .models import STTResult

logger = logging.getLogger(__name__)

# NeMo íŒ¨í‚¤ì§€ ê°€ì ¸ì˜¤ê¸° ì‹œë„
try:
    import nemo
    import nemo.collections.asr as nemo_asr
    from omegaconf import DictConfig, OmegaConf
    NEMO_AVAILABLE = True
    logger.info("âœ… NeMo íŒ¨í‚¤ì§€ ê°€ì ¸ì˜¤ê¸° ì„±ê³µ")
except ImportError as e:
    NEMO_AVAILABLE = False
    logger.warning(f"âš ï¸ NeMo íŒ¨í‚¤ì§€ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    logger.warning("NeMo ëª¨ë¸ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install nemo-toolkit[asr]'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")


class NeMoSTTService(BaseSTTService):
    """NeMo ASR ì„œë¹„ìŠ¤"""
    
    def __init__(self, model_name: str = "./FastConformer-Transducer-BPE_9.75.nemo", device: str = "cuda", **kwargs):
        super().__init__(model_name, device, **kwargs)
        self.model: Optional[Any] = None
        
        if not NEMO_AVAILABLE:
            raise ImportError("NeMo íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install nemo-toolkit[asr] omegaconf hydra-core'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
    
    def _configure_nemo_compatibility(self):
        """NeMo í˜¸í™˜ì„± ì„¤ì •"""
        try:
            # use_pytorch_sdpa í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
            import os
            os.environ['NEMO_DISABLE_PYTORCH_SDPA'] = '1'
            os.environ['PYTORCH_DISABLE_SDPA'] = '1'
            
            # OmegaConf ì„¤ì •
            from omegaconf import OmegaConf
            OmegaConf.set_struct(OmegaConf.create({}), False)
            
            logger.info("ğŸ”§ NeMo í˜¸í™˜ì„± ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âš ï¸ NeMo í˜¸í™˜ì„± ì„¤ì • ì‹¤íŒ¨ (ë¹„ì¤‘ìš”): {e}")
    
    def _optimize_decoding_config(self):
        """NeMo ëª¨ë¸ì˜ ë””ì½”ë”© ì„¤ì • ìµœì í™”"""
        try:
            logger.info("ğŸ”§ NeMo ë””ì½”ë”© ì„¤ì • ìµœì í™” ì‹œì‘...")
            
            if not hasattr(self.model, 'cfg'):
                logger.warning("âš ï¸ ëª¨ë¸ì— cfg ì†ì„±ì´ ì—†ì–´ ë””ì½”ë”© ìµœì í™” ê±´ë„ˆëœ€")
                return
            
            cfg = self.model.cfg
            
            # ì–¸ì–´ ì„¤ì •
            if hasattr(cfg, 'language'):
                logger.info(f"ğŸ‡°ğŸ‡· ê¸°ì¡´ ì–¸ì–´ ì„¤ì •: {cfg.language}")
                cfg.language = 'ko'
                logger.info("ğŸ‡°ğŸ‡· í•œêµ­ì–´ë¡œ ì–¸ì–´ ì„¤ì • ë³€ê²½")
            
            # ë””ì½”ë”© ì„¤ì • ìµœì í™”
            if hasattr(cfg, 'decoding'):
                decoding = cfg.decoding
                logger.info(f"ğŸ”§ ê¸°ì¡´ ë””ì½”ë”© ì „ëµ: {getattr(decoding, 'strategy', 'Unknown')}")
                
                # ë¹” ì„œì¹˜ ì„¤ì • ìµœì í™”
                if hasattr(decoding, 'beam'):
                    beam = decoding.beam
                    original_beam_size = getattr(beam, 'beam_size', 1)
                    
                    # ë¹” í¬ê¸° ì¦ê°€ (ë” ì •í™•í•œ ê²°ê³¼, ë‹¨ì–´ ëˆ„ë½ ë°©ì§€)
                    beam.beam_size = max(4, original_beam_size)  # 6 â†’ 4ë¡œ ê°ì†Œ
                    
                    # ê¸¸ì´ ì •ê·œí™” ê°œì„  (ë” ê¸´ ë¬¸ì¥ ì„ í˜¸)
                    if hasattr(beam, 'len_pen'):
                        beam.len_pen = 0.5  # ê¸¸ì´ íŒ¨ë„í‹° ì¡°ì • (0.3 â†’ 0.5ë¡œ ì¦ê°€)
                    
                    logger.info(f"ğŸ”§ ë¹” í¬ê¸°: {original_beam_size} -> {beam.beam_size}")
                    logger.info(f"ğŸ”§ ê¸¸ì´ ì •ê·œí™”: {getattr(beam, 'len_pen', 'Unknown')}")
                
                # ì „ëµë³„ ì„¤ì •
                strategy = getattr(decoding, 'strategy', 'greedy')
                if strategy == 'greedy':
                    # ê·¸ë¦¬ë””ì—ì„œ ë¹” ì„œì¹˜ë¡œ ë³€ê²½ ì‹œë„
                    try:
                        from omegaconf import DictConfig, OmegaConf
                        
                        # ë¹” ì„œì¹˜ ì„¤ì • ìƒì„± (ë‹¨ì–´ ëˆ„ë½ ë°©ì§€ ì„¤ì •)
                        beam_config = DictConfig({
                            'beam_size': 4,  # ë” ë³´ìˆ˜ì ì¸ ë¹” í¬ê¸° (6 â†’ 4)
                            'len_pen': 0.5,  # ì ì ˆí•œ ê¸¸ì´ íŒ¨ë„í‹°
                            'max_generation_delta': -1,
                            'score_norm': True,  # ì ìˆ˜ ì •ê·œí™”
                            'return_best_hypothesis': True  # ìµœê³  ê°€ì„¤ë§Œ ë°˜í™˜
                        })
                        
                        # ë””ì½”ë”© ì„¤ì • ì—…ë°ì´íŠ¸
                        decoding.strategy = 'beam'
                        decoding.beam = beam_config
                        
                        logger.info("ğŸ”§ ê·¸ë¦¬ë””ì—ì„œ ë¹” ì„œì¹˜ë¡œ ë³€ê²½")
                    except Exception as e:
                        logger.warning(f"âš ï¸ ë¹” ì„œì¹˜ ë³€ê²½ ì‹¤íŒ¨: {e}")
            
            # ëª¨ë¸ì— ë³€ê²½ëœ ì„¤ì • ì ìš©
            if hasattr(self.model, 'change_decoding_strategy'):
                try:
                    self.model.change_decoding_strategy(cfg.decoding)
                    logger.info("âœ… ë””ì½”ë”© ì „ëµ ë³€ê²½ ì ìš© ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ ë””ì½”ë”© ì „ëµ ë³€ê²½ ì ìš© ì‹¤íŒ¨: {e}")
            
            logger.info("âœ… NeMo ë””ì½”ë”© ì„¤ì • ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ë””ì½”ë”© ì„¤ì • ìµœì í™” ì‹¤íŒ¨: {e}")
            import traceback

    
    def _patch_model_config(self, model_path):
        """ëª¨ë¸ ì„¤ì •ì—ì„œ í˜¸í™˜ì„± ë¬¸ì œê°€ ìˆëŠ” íŒŒë¼ë¯¸í„° ì œê±°"""
        try:
            import tempfile
            import tarfile
            import yaml
            import os
            from omegaconf import OmegaConf
            
            # .nemo íŒŒì¼ì„ ì„ì‹œë¡œ ì••ì¶• í•´ì œ
            with tempfile.TemporaryDirectory() as temp_dir:
                with tarfile.open(model_path, 'r') as tar:
                    tar.extractall(temp_dir)
                
                # model_config.yaml ìˆ˜ì •
                config_path = os.path.join(temp_dir, 'model_config.yaml')
                if os.path.exists(config_path):
                    with open(config_path, 'r') as f:
                        config = yaml.safe_load(f)
                    
                    # SDPA ê´€ë ¨ ëª¨ë“  íŒŒë¼ë¯¸í„°ë“¤ì„ ì œê±°
                    sdpa_keywords = [
                        'use_pytorch_sdpa',
                        'use_pytorch_sdpa_backends',
                        'pytorch_sdpa',
                        'sdpa_backends',
                        'enable_flash_attention',
                        'flash_attention'
                    ]
                    
                    def remove_problematic_params(cfg, path="root"):
                        if isinstance(cfg, dict):
                            # SDPA ê´€ë ¨ í‚¤ ì œê±°
                            keys_to_remove = []
                            for key in cfg.keys():
                                for keyword in sdpa_keywords:
                                    if keyword in key.lower():
                                        keys_to_remove.append(key)
                                        break
                            
                            for key in keys_to_remove:
                                logger.info(f"ğŸ”§ {path}.{key} íŒŒë¼ë¯¸í„° ì œê±°")
                                del cfg[key]
                            
                            # ëª¨ë“  í•˜ìœ„ ë”•ì…”ë„ˆë¦¬ì— ëŒ€í•´ì„œë„ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
                            for key, value in cfg.items():
                                if isinstance(value, dict):
                                    remove_problematic_params(value, f"{path}.{key}")
                                elif isinstance(value, list):
                                    for i, item in enumerate(value):
                                        if isinstance(item, dict):
                                            remove_problematic_params(item, f"{path}.{key}[{i}]")
                    
                    remove_problematic_params(config)
                    
                    # ì¶”ê°€ë¡œ encoder ì„¤ì •ì—ì„œ íŠ¹ì • ë¬¸ì œ íŒŒë¼ë¯¸í„°ë“¤ ì œê±°
                    if 'encoder' in config:
                        encoder_config = config['encoder']
                        if isinstance(encoder_config, dict):
                            # Conformer encoderì˜ ë¬¸ì œê°€ ë˜ëŠ” íŒŒë¼ë¯¸í„°ë“¤ ì œê±°
                            problematic_keys = [
                                'use_pytorch_sdpa_backends',
                                'use_pytorch_sdpa',
                                'self_attention_model',
                                'rel_pos_enc_type'
                            ]
                            
                            for key in problematic_keys:
                                if key in encoder_config:
                                    logger.info(f"ğŸ”§ encoder.{key} íŒŒë¼ë¯¸í„° ì œê±°")
                                    del encoder_config[key]
                    
                    # ìˆ˜ì •ëœ ì„¤ì • ì €ì¥
                    with open(config_path, 'w') as f:
                        yaml.safe_dump(config, f)
                    
                    # ìƒˆë¡œìš´ .nemo íŒŒì¼ ìƒì„±
                    patched_path = model_path.replace('.nemo', '_patched.nemo')
                    with tarfile.open(patched_path, 'w') as tar:
                        for item in os.listdir(temp_dir):
                            tar.add(os.path.join(temp_dir, item), arcname=item)
                    
                    logger.info(f"âœ… íŒ¨ì¹˜ëœ ëª¨ë¸ ìƒì„±: {patched_path}")
                    return patched_path
                else:
                    logger.warning("âš ï¸ model_config.yamlì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                    return model_path
                    
        except Exception as e:
            logger.warning(f"âš ï¸ ëª¨ë¸ ì„¤ì • íŒ¨ì¹˜ ì‹¤íŒ¨: {e}")
            return model_path

    async def initialize(self) -> bool:
        """NeMo ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            logger.info(f"ğŸ¤– NeMo STT ëª¨ë¸ ì´ˆê¸°í™” ì¤‘: {self.model_name}")
            start_time = time.time()
            
            # NeMo í˜¸í™˜ì„± ì„¤ì •
            self._configure_nemo_compatibility()
            
            # ëª¨ë¸ ê²½ë¡œ ì²˜ë¦¬
            import os
            if self.model_name.startswith('./'):
                # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                model_path = os.path.abspath(self.model_name)
                logger.info(f"ğŸ“‚ ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜: {self.model_name} -> {model_path}")
            else:
                model_path = self.model_name
            
            # ëª¨ë¸ ë¡œë“œ ë°©ì‹ ê°œì„ 
            if model_path.endswith('.nemo') or os.path.exists(model_path):
                # ë¡œì»¬ .nemo íŒŒì¼ ë¡œë“œ
                logger.info(f"ğŸ“¦ ë¡œì»¬ .nemo íŒŒì¼ ë¡œë“œ ì¤‘: {model_path}")
                if not os.path.exists(model_path):
                    raise FileNotFoundError(f"ë¡œì»¬ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
                
                # í˜¸í™˜ì„± ë¬¸ì œê°€ ìˆëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì œê±°í•œ íŒ¨ì¹˜ëœ ëª¨ë¸ ìƒì„±
                logger.info("ğŸ”§ ëª¨ë¸ í˜¸í™˜ì„± íŒ¨ì¹˜ ì ìš© ì¤‘...")
                patched_model_path = self._patch_model_config(model_path)
                
                # restore_fromì„ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ .nemo íŒŒì¼ ë¡œë“œ
                try:
                    # ë¨¼ì € RNN-T BPE ëª¨ë¸ë¡œ ì‹œë„ (FastConformer-Transducerì— ì í•©)
                    from nemo.collections.asr.models.rnnt_bpe_models import EncDecRNNTBPEModel
                    logger.info("ğŸ”„ EncDecRNNTBPEModelë¡œ ë¡œë“œ ì‹œë„ ì¤‘...")
                    
                    # ì¶”ê°€ ë¡œë“œ ì˜µì…˜
                    load_options = {
                        'strict': False,
                        'map_location': 'cpu' if self.device == 'cpu' else None
                    }
                    
                    self.model = EncDecRNNTBPEModel.restore_from(patched_model_path, **load_options)
                    logger.info("âœ… EncDecRNNTBPEModelë¡œ ë¡œë“œ ì„±ê³µ")
                    
                except Exception as e1:
                    logger.warning(f"âš ï¸ EncDecRNNTBPEModelë¡œ ë¡œë“œ ì‹¤íŒ¨: {e1}")
                    try:
                        # CTC BPE ëª¨ë¸ë¡œ ì‹œë„ (ì˜¬ë°”ë¥¸ í´ë˜ìŠ¤ëª… ì‚¬ìš©)
                        from nemo.collections.asr.models.ctc_models import EncDecCTCModel
                        logger.info("ğŸ”„ EncDecCTCModelë¡œ ë¡œë“œ ì‹œë„ ì¤‘...")
                        self.model = EncDecCTCModel.restore_from(patched_model_path, strict=False)
                        logger.info("âœ… EncDecCTCModelë¡œ ë¡œë“œ ì„±ê³µ")
                    except Exception as e2:
                        logger.warning(f"âš ï¸ EncDecCTCModelë¡œ ë¡œë“œ ì‹¤íŒ¨: {e2}")
                        try:
                            # ë§ˆì§€ë§‰ìœ¼ë¡œ ì¼ë°˜ ASRModelë¡œ ì‹œë„
                            logger.info("ğŸ”„ ì¼ë°˜ ASRModelë¡œ ë¡œë“œ ì‹œë„ ì¤‘...")
                            self.model = nemo_asr.models.ASRModel.restore_from(patched_model_path, strict=False)
                            logger.info("âœ… ì¼ë°˜ ASRModelë¡œ ë¡œë“œ ì„±ê³µ")
                        except Exception as e3:
                            logger.error(f"âŒ ëª¨ë“  ë¡œì»¬ ë¡œë“œ ë°©ë²• ì‹¤íŒ¨: {e3}")
                            # íŒ¨ì¹˜ëœ íŒŒì¼ ì •ë¦¬
                            if patched_model_path != model_path and os.path.exists(patched_model_path):
                                os.remove(patched_model_path)
                                logger.info("ğŸ§¹ íŒ¨ì¹˜ëœ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                            raise Exception(f"ëª¨ë“  NeMo ëª¨ë¸ ë¡œë“œ ë°©ë²•ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì—ëŸ¬: {e3}")
            else:
                # Hugging Face ëª¨ë¸ ë¡œë“œ
                logger.info(f"ğŸ“¦ Hugging Faceì—ì„œ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}")
                try:
                    # ë¨¼ì € EncDecRNNTBPEModelë¡œ ì‹œë„
                    from nemo.collections.asr.models.rnnt_bpe_models import EncDecRNNTBPEModel
                    self.model = EncDecRNNTBPEModel.from_pretrained(model_path)
                except Exception as e1:
                    logger.warning(f"âš ï¸ EncDecRNNTBPEModelë¡œ ë¡œë“œ ì‹¤íŒ¨: {e1}")
                    try:
                        # EncDecCTCModelë¡œ ì‹œë„
                        from nemo.collections.asr.models.ctc_bpe_models import EncDecCTCBPEModel
                        self.model = EncDecCTCBPEModel.from_pretrained(model_path)
                    except Exception as e2:
                        logger.warning(f"âš ï¸ EncDecCTCBPEModelë¡œ ë¡œë“œ ì‹¤íŒ¨: {e2}")
                        # ë§ˆì§€ë§‰ìœ¼ë¡œ ì¼ë°˜ ASRModelë¡œ ì‹œë„
                        self.model = nemo_asr.models.ASRModel.from_pretrained(model_path)
            
            # GPUë¡œ ëª¨ë¸ ì´ë™
            if torch.cuda.is_available() and self.device == "cuda":
                self.model = self.model.to('cuda')
                logger.info(f"âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™: {torch.cuda.get_device_name(0)}")
            
            # í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
            self.model.eval()
            
            # NeMo ëª¨ë¸ ë””ì½”ë”© ì„¤ì • ìµœì í™”
            self._optimize_decoding_config()
            
            # ëª¨ë¸ ìµœì í™” ì„¤ì •
            if torch.cuda.is_available() and self.device == "cuda":
                # ì»´íŒŒì¼ ìµœì í™” (PyTorch 2.0+)
                try:
                    if hasattr(torch, 'compile'):
                        logger.info("ğŸ”§ PyTorch 2.0 ì»´íŒŒì¼ ìµœì í™” ì ìš© ì¤‘...")
                        self.model = torch.compile(self.model, mode='reduce-overhead')
                        logger.info("âœ… PyTorch ì»´íŒŒì¼ ìµœì í™” ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ PyTorch ì»´íŒŒì¼ ìµœì í™” ì‹¤íŒ¨: {e}")
            
            load_time = time.time() - start_time
            logger.info(f"âœ… NeMo STT ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ: {load_time:.2f}ì´ˆ")
            
            # ì›œì—… ìˆ˜í–‰
            await self._warmup_model()
            
            # íŒ¨ì¹˜ëœ ì„ì‹œ íŒŒì¼ ì •ë¦¬ (ëª¨ë¸ì´ ë©”ëª¨ë¦¬ì— ë¡œë“œëœ í›„)
            if 'patched_model_path' in locals() and patched_model_path != model_path and os.path.exists(patched_model_path):
                try:
                    os.remove(patched_model_path)
                    logger.info("ğŸ§¹ íŒ¨ì¹˜ëœ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            
            self.is_initialized = True
            self.initialization_error = None
            return True
            
        except Exception as e:
            error_msg = f"NeMo ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            self.initialization_error = error_msg
            self.is_initialized = False
            return False
    
    async def _warmup_model(self):
        """ëª¨ë¸ ì›œì—… (ì²« ìš”ì²­ ì§€ì—° ìµœì†Œí™”)"""
        try:
            logger.info("ğŸ”¥ NeMo ëª¨ë¸ ì›œì—… ì‹œì‘...")
            
            # ë”ë¯¸ ì˜¤ë””ì˜¤ ë°ì´í„° ìƒì„± (1ì´ˆ, 16kHz)
            dummy_audio = np.random.randn(16000).astype(np.float32) * 0.1
            
            # ì›œì—… ì „ì‚¬ ìˆ˜í–‰
            start_time = time.time()
            await self.transcribe(dummy_audio, language="ko")
            warmup_time = time.time() - start_time
            
            logger.info(f"âœ… NeMo ëª¨ë¸ ì›œì—… ì™„ë£Œ ({warmup_time:.3f}ì´ˆ)")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ëª¨ë¸ ì›œì—… ì‹¤íŒ¨ (ë¹„ì¤‘ìš”): {e}")
    
    async def transcribe(self, audio_data: np.ndarray, **kwargs) -> Dict[str, Any]:
        """NeMo ëª¨ë¸ì„ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹ (ë‹¤ì¤‘ í›„ë³´ ì²˜ë¦¬)"""
        try:
            logger.info("ğŸ¤ NeMo STT ì „ì‚¬ ì‹œì‘")
            
            # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
            processed_audio = self._preprocess_audio(audio_data)
            
            # ê¸°ë³¸ ì „ì‚¬ ìˆ˜í–‰
            logger.info("ğŸ”„ ê¸°ë³¸ ì „ì‚¬ ìˆ˜í–‰ ì¤‘...")
            results = self.model.transcribe([processed_audio])
            
            # ì—¬ëŸ¬ í›„ë³´ë¥¼ ìƒì„±í•˜ëŠ” ì¶”ê°€ ì „ì‚¬ (ë¹” ì„œì¹˜ í™œìš©)
            try:
                logger.info("ğŸ”„ ë‹¤ì¤‘ í›„ë³´ ìƒì„±ì„ ìœ„í•œ ì¶”ê°€ ì „ì‚¬...")
                
                # í˜„ì¬ ë¹” í¬ê¸° í™•ì¸
                current_beam_size = 1
                if hasattr(self.model, 'cfg') and hasattr(self.model.cfg, 'decoding'):
                    decoding = self.model.cfg.decoding
                    if hasattr(decoding, 'beam') and hasattr(decoding.beam, 'beam_size'):
                        current_beam_size = decoding.beam.beam_size
                
                # ë” ë§ì€ í›„ë³´ë¥¼ ìœ„í•´ ë¹” í¬ê¸° ì„ì‹œ ì¦ê°€
                if current_beam_size < 6:  # 8 â†’ 6ìœ¼ë¡œ ê°ì†Œ
                    logger.info(f"ğŸ”§ ë¹” í¬ê¸° ì„ì‹œ ì¦ê°€: {current_beam_size} â†’ 6")  # 8 â†’ 6
                    
                    # ì›ë³¸ ì„¤ì • ë°±ì—…
                    original_beam_size = current_beam_size
                    
                    # ë¹” í¬ê¸° ì¦ê°€
                    if hasattr(decoding, 'beam'):
                        decoding.beam.beam_size = 6  # 8 â†’ 6ìœ¼ë¡œ ê°ì†Œ
                        decoding.beam.return_best_hypothesis = True
                    
                    # ë‹¤ì‹œ ì „ì‚¬
                    additional_results = self.model.transcribe([processed_audio])
                    
                    # ì›ë³¸ ì„¤ì • ë³µì›
                    decoding.beam.beam_size = original_beam_size
                    
                    # ê²°ê³¼ ë³‘í•©
                    if additional_results and len(additional_results) > 0:
                        logger.info(f"ğŸ“ ì¶”ê°€ í›„ë³´ {len(additional_results)}ê°œ ìƒì„±")
                        # ê¸°ë³¸ ê²°ê³¼ì™€ ì¶”ê°€ ê²°ê³¼ë¥¼ í•¨ê»˜ ê³ ë ¤
                        all_candidates = []
                        
                        # ê¸°ë³¸ ê²°ê³¼ ì¶”ê°€
                        base_text = self._extract_text_from_result(results)
                        if base_text.strip():
                            all_candidates.append({
                                'text': base_text.strip(),
                                'confidence': self._calculate_text_confidence(base_text),
                                'source': 'base'
                            })
                        
                        # ì¶”ê°€ ê²°ê³¼ë“¤ ì¶”ê°€
                        for i, add_result in enumerate(additional_results):
                            add_text = self._extract_text_from_result(add_result)
                            if add_text.strip() and add_text.strip() != base_text.strip():
                                all_candidates.append({
                                    'text': add_text.strip(),
                                    'confidence': self._calculate_text_confidence(add_text),
                                    'source': f'beam_{i}'
                                })
                        
                        # ìµœê³  ì‹ ë¢°ë„ í›„ë³´ ì„ íƒ
                        if all_candidates:
                            best_candidate = max(all_candidates, key=lambda x: x['confidence'])
                            logger.info(f"ğŸ† ìµœì  í›„ë³´ ì„ íƒ: '{best_candidate['text']}' (ì‹ ë¢°ë„: {best_candidate['confidence']:.3f}, ì¶œì²˜: {best_candidate['source']})")
                            
                            # ë‹¤ë¥¸ í›„ë³´ë“¤ë„ ë¡œê¹…
                            for i, candidate in enumerate(all_candidates):
                                if candidate != best_candidate:
                                    logger.info(f"   í›„ë³´ {i+1}: '{candidate['text']}' (ì‹ ë¢°ë„: {candidate['confidence']:.3f})")
                            
                            # ìµœì  ê²°ê³¼ë¡œ ëŒ€ì²´
                            results = [best_candidate['text']]
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë‹¤ì¤‘ í›„ë³´ ì²˜ë¦¬ ì‹¤íŒ¨, ê¸°ë³¸ ê²°ê³¼ ì‚¬ìš©: {e}")
            
            # ìµœì¢… í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = self._extract_text_from_result(results)
            
            if not text.strip():
                logger.warning("âš ï¸ ì „ì‚¬ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
                return {
                    'text': '',
                    'confidence': 0.0,
                    'segments': [],
                    'model': self.model_name
                }
            
            # ê²°ê³¼ ì¤€ë¹„
            audio_duration = len(audio_data) / 16000.0
            confidence = self._calculate_confidence(text, audio_duration)
            segments = self._create_segments(text, audio_duration)
            
            logger.info(f"âœ… NeMo ì „ì‚¬ ì™„ë£Œ: '{text[:100]}{'...' if len(text) > 100 else ''}' (ì‹ ë¢°ë„: {confidence:.3f})")
            
            return {
                'text': text,
                'confidence': confidence,
                'segments': segments,
                'model': self.model_name,
                'duration': audio_duration
            }
            
        except Exception as e:
            logger.error(f"âŒ NeMo STT ì „ì‚¬ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(f"ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            
            return {
                'text': '',
                'confidence': 0.0,
                'segments': [],
                'model': self.model_name,
                'error': str(e)
            }
    
    async def transcribe_audio(self, audio_data: str, audio_format: str = "pcm_16khz", language: str = "ko", **kwargs) -> STTResult:
        """ì˜¤ë””ì˜¤ ì „ì‚¬ (ê¸°ë³¸ ì§„ì…ì ) - ê¸¸ì´ì— ë”°ë¼ ë‹¨ì¼/ì²­í¬ ì²˜ë¦¬ ìë™ ì„ íƒ"""
        print("ğŸš¨ğŸš¨ğŸš¨ NeMo transcribe_audio í•¨ìˆ˜ ì‹œì‘! ğŸš¨ğŸš¨ğŸš¨")
        logger.info("ğŸš¨ğŸš¨ğŸš¨ NeMo transcribe_audio í•¨ìˆ˜ ì‹œì‘! ğŸš¨ğŸš¨ğŸš¨")
        try:
            import base64
            import numpy as np
            import tempfile
            import wave
            import os
            
            logger.info("=" * 100)
            logger.info("ğŸ¯ NeMo transcribe_audio í•¨ìˆ˜ í˜¸ì¶œë¨")
            logger.info("=" * 100)
            logger.info(f"ğŸ“¥ ì…ë ¥ íŒŒë¼ë¯¸í„°:")
            logger.info(f"   â€¢ audio_format: {audio_format}")
            logger.info(f"   â€¢ language: {language}")
            logger.info(f"   â€¢ audio_data ê¸¸ì´: {len(audio_data)} chars")
            
            # base64 ë””ì½”ë”© ë° ì˜¤ë””ì˜¤ ë°ì´í„° ë³€í™˜
            if audio_format == "pcm_16khz":
                audio_bytes = base64.b64decode(audio_data)
                audio_array = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
                logger.info(f"ğŸ”„ PCM 16kHz ë””ì½”ë”© ì™„ë£Œ: {len(audio_array)} ìƒ˜í”Œ")
            elif audio_format == "wav":
                # WAV íŒŒì¼ ì²˜ë¦¬
                import tempfile
                import wave
                import os
                
                print(f"ğŸš¨ WAV ì²˜ë¦¬ ì‹œì‘! audio_data ê¸¸ì´: {len(audio_data)}")
                logger.info(f"ğŸ”„ WAV ì²˜ë¦¬ ì‹œì‘ - audio_data ê¸¸ì´: {len(audio_data)} chars")
                
                try:
                    audio_bytes = base64.b64decode(audio_data)
                    print(f"ğŸš¨ base64 ë””ì½”ë”© ì™„ë£Œ! audio_bytes ê¸¸ì´: {len(audio_bytes)}")
                    logger.info(f"ğŸ”„ base64 ë””ì½”ë”© ì™„ë£Œ - audio_bytes ê¸¸ì´: {len(audio_bytes)} bytes")
                except Exception as e:
                    print(f"ğŸš¨ base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
                    logger.error(f"âŒ base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
                    raise
                
                # ì„ì‹œ WAV íŒŒì¼ ìƒì„±
                try:
                    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_wav:
                        temp_wav.write(audio_bytes)
                        temp_wav_path = temp_wav.name
                    print(f"ğŸš¨ ì„ì‹œ WAV íŒŒì¼ ìƒì„±: {temp_wav_path}")
                    logger.info(f"ğŸ”„ ì„ì‹œ WAV íŒŒì¼ ìƒì„±: {temp_wav_path}")
                except Exception as e:
                    print(f"ğŸš¨ ì„ì‹œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
                    logger.error(f"âŒ ì„ì‹œ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
                    raise
                
                try:
                    # WAV íŒŒì¼ì„ numpy ë°°ì—´ë¡œ ì½ê¸°
                    print("ğŸš¨ WAV íŒŒì¼ ì½ê¸° ì‹œì‘...")
                    with wave.open(temp_wav_path, 'rb') as wav_file:
                        frames = wav_file.readframes(wav_file.getnframes())
                        audio_array = np.frombuffer(frames, dtype=np.int16).astype(np.float32) / 32768.0
                        sample_rate = wav_file.getframerate()
                        
                        print(f"ğŸš¨ WAV íŒŒì¼ ì½ê¸° ì™„ë£Œ! sample_rate: {sample_rate}, ìƒ˜í”Œ ìˆ˜: {len(audio_array)}")
                        logger.info(f"ğŸ”„ WAV íŒŒì¼ ì½ê¸° ì™„ë£Œ - sample_rate: {sample_rate}, ìƒ˜í”Œ ìˆ˜: {len(audio_array)}")
                        
                        # 16kHzë¡œ ë¦¬ìƒ˜í”Œë§ì´ í•„ìš”í•œ ê²½ìš°
                        if sample_rate != 16000:
                            print(f"ğŸš¨ ë¦¬ìƒ˜í”Œë§ ì‹œì‘: {sample_rate} -> 16000")
                            import librosa
                            audio_array = librosa.resample(audio_array, orig_sr=sample_rate, target_sr=16000)
                            print(f"ğŸš¨ ë¦¬ìƒ˜í”Œë§ ì™„ë£Œ! ìƒˆ ìƒ˜í”Œ ìˆ˜: {len(audio_array)}")
                            logger.info(f"ğŸ”„ {sample_rate}Hz -> 16kHz ë¦¬ìƒ˜í”Œë§ ì™„ë£Œ")
                        else:
                            print("ğŸš¨ ë¦¬ìƒ˜í”Œë§ ë¶ˆí•„ìš” - ì´ë¯¸ 16kHz")
                            
                except Exception as e:
                    print(f"ğŸš¨ WAV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                    logger.error(f"âŒ WAV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
                    raise
                finally:
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    try:
                        if os.path.exists(temp_wav_path):
                            os.unlink(temp_wav_path)
                            print(f"ğŸš¨ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì™„ë£Œ: {temp_wav_path}")
                    except Exception as e:
                        print(f"ğŸš¨ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
                        logger.warning(f"âš ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹: {audio_format}")
            
            # ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚° (ì´ˆ ë‹¨ìœ„)
            audio_duration = len(audio_array) / 16000.0
            print(f"ğŸš¨ ì˜¤ë””ì˜¤ ê¸¸ì´ ê³„ì‚° ì™„ë£Œ: {audio_duration:.2f}ì´ˆ (ìƒ˜í”Œ ìˆ˜: {len(audio_array)})")
            logger.info(f"ğŸ§ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.2f}ì´ˆ")
            
            # 20ì´ˆ ê¸°ì¤€ ë¶„ê¸°ì  ë¡œê¹…
            chunk_threshold = 20.0  # 20ì´ˆ ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
            print(f"ğŸš¨ ì²­í¬ ë¶„í•  ì„ê³„ê°’: {chunk_threshold}ì´ˆ")
            print(f"ğŸš¨ ì¡°ê±´ ì²´í¬: {audio_duration} >= {chunk_threshold} = {audio_duration >= chunk_threshold}")
            logger.info(f"ğŸ” ì²­í¬ ë¶„í•  ì„ê³„ê°’: {chunk_threshold}ì´ˆ")
            logger.info(f"ğŸ” ì˜¤ë””ì˜¤ ê¸¸ì´ >= ì„ê³„ê°’? {audio_duration} >= {chunk_threshold} = {audio_duration >= chunk_threshold}")
            
            if audio_duration >= chunk_threshold:
                print(f"ğŸš¨ ì²­í¬ ë¶„í•  ì²˜ë¦¬ë¡œ ì§„ì…! ({audio_duration:.1f}ì´ˆ)")
                logger.info(f"ğŸ“¦ 20ì´ˆ ì´ìƒ ì˜¤ë””ì˜¤ ê°ì§€ ({audio_duration:.1f}ì´ˆ) - VAD ê¸°ë°˜ ì²­í¬ ë¶„í•  ì²˜ë¦¬ (10ì´ˆ ì œí•œ)")
                return await self._transcribe_with_chunks(audio_array, audio_duration, 10.0)
            else:
                # 20ì´ˆ ë¯¸ë§Œ ì˜¤ë””ì˜¤ëŠ” VAD ì—†ì´ ì „ì²´ ì²˜ë¦¬
                print(f"ğŸš¨ ë‹¨ì¼ ì²˜ë¦¬ë¡œ ì§„ì…! ({audio_duration:.1f}ì´ˆ)")
                logger.info(f"ğŸš€ 20ì´ˆ ë¯¸ë§Œ ì˜¤ë””ì˜¤ ({audio_duration:.1f}ì´ˆ) - VAD ì—†ì´ ì „ì²´ ì²˜ë¦¬")
                return await self._transcribe_single(audio_array, audio_duration)
                
        except Exception as e:
            print(f"ğŸš¨ğŸš¨ğŸš¨ NeMo transcribe_audio ì—ëŸ¬: {e}")
            logger.error(f"âŒ NeMo transcribe_audio ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            raise ValueError(f"NeMo ì „ì‚¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
    
    async def _transcribe_single(self, audio_array: np.ndarray, audio_duration: float) -> STTResult:
        """ë‹¨ì¼ ì˜¤ë””ì˜¤ ì²˜ë¦¬ (VAD ì—†ì´ ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬)"""
        try:
            start_time = time.time()
            
            logger.info("=" * 60)
            logger.info("ğŸš€ VAD ì—†ì´ ì „ì²´ ì˜¤ë””ì˜¤ ë‹¨ì¼ ì²˜ë¦¬ ì‹œì‘")
            logger.info("=" * 60)
            logger.info(f"ğŸ“ ì „ì²´ ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration:.2f}ì´ˆ")
            logger.info(f"ğŸ¯ ì²˜ë¦¬ ë°©ì‹: VAD ë¶„í•  ì—†ì´ ì „ì²´ ì˜¤ë””ì˜¤ í•œ ë²ˆì— ì „ì‚¬")
            logger.info(f"ğŸ’¡ ì´ ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ ì•ë¶€ë¶„ ì†ì‹¤ ë¬¸ì œê°€ ì—†ì–´ì•¼ í•©ë‹ˆë‹¤")
            
            # NeMo ëª¨ë¸ë¡œ ì „ì‚¬ (ê°„ë‹¨í•œ ì ‘ê·¼ë²•)
            logger.info("ğŸ¤– NeMo ëª¨ë¸ ì „ì‚¬ ì¤‘...")
            
            # torch dynamo ì—ëŸ¬ ì–µì œ
            import torch._dynamo
            torch._dynamo.config.suppress_errors = True
            
            try:
                # ì„ì‹œ WAV íŒŒì¼ë¡œ ì €ì¥í•´ì„œ transcribe
                import tempfile
                import soundfile as sf
                import os
                
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                    temp_path = temp_file.name
                
                # WAV íŒŒì¼ë¡œ ì €ì¥
                sf.write(temp_path, audio_array, 16000, subtype='PCM_16')
                
                try:
                    # í•œêµ­ì–´ ì„¤ì • ì‹œë„
                    try:
                        if hasattr(self.model, 'cfg') and hasattr(self.model.cfg, 'language'):
                            logger.info("ğŸ‡°ğŸ‡· ë‹¨ì¼ ì²˜ë¦¬ - ëª¨ë¸ì— í•œêµ­ì–´ ì„¤ì • ì ìš© ì¤‘...")
                            original_language = getattr(self.model.cfg, 'language', None)
                            self.model.cfg.language = 'ko'
                    except Exception as e:
                        logger.warning(f"âš ï¸ ë‹¨ì¼ ì²˜ë¦¬ - ì–¸ì–´ ì„¤ì • ì ìš© ì‹¤íŒ¨: {e}")
                    
                    # íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©í•´ì„œ transcribe
                    result = self.model.transcribe([temp_path])
                finally:
                    # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                    if os.path.exists(temp_path):
                        os.unlink(temp_path)
                        
            except Exception as file_error:
                logger.warning(f"âš ï¸ íŒŒì¼ ê¸°ë°˜ ì „ì‚¬ ì‹¤íŒ¨: {file_error}")
                # ë¹ˆ ê²°ê³¼ ë°˜í™˜
                result = [""]
            
            # ë””ë²„ê¹…: ì›ì‹œ ê²°ê³¼ ë¡œê¹…
            logger.info(f"ğŸ” NeMo ì›ì‹œ ê²°ê³¼ íƒ€ì…: {type(result)}")
            if hasattr(result, '__len__'):
                logger.info(f"ğŸ” ê²°ê³¼ ê¸¸ì´: {len(result)}")
            if isinstance(result, (list, tuple)) and len(result) > 0:
                logger.info(f"ğŸ” ì²« ë²ˆì§¸ ìš”ì†Œ íƒ€ì…: {type(result[0])}")
                if hasattr(result[0], '__len__') and len(str(result[0])) < 200:
                    logger.info(f"ğŸ” ì²« ë²ˆì§¸ ìš”ì†Œ ë‚´ìš©: {result[0]}")
            
            # ê²°ê³¼ ì¶”ì¶œ
            text = self._extract_text_from_result(result)
            processing_time = time.time() - start_time
            rtf = processing_time / audio_duration if audio_duration > 0 else 0.0
            
            logger.info("-" * 60)
            logger.info("ğŸ” ë‹¨ì¼ ì²˜ë¦¬ ê²°ê³¼ ë¶„ì„:")
            logger.info(f"   ğŸ“ ì „ì²´ ì „ì‚¬ í…ìŠ¤íŠ¸: '{text}'")
            logger.info(f"   ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì")
            logger.info(f"   â±ï¸ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            logger.info(f"   ğŸš€ RTF: {rtf:.3f}")
            
            # "ì½”ë¡œë‚˜" í‚¤ì›Œë“œ ì²´í¬
            if "ì½”ë¡œë‚˜" in text:
                logger.info("   âœ… 'ì½”ë¡œë‚˜' í‚¤ì›Œë“œ ë°œê²¬! - VAD ì—†ì´ ì •ìƒ ì²˜ë¦¬ë¨")
            else:
                logger.warning("   âš ï¸ 'ì½”ë¡œë‚˜' í‚¤ì›Œë“œ ëˆ„ë½ - ëª¨ë¸ ìì²´ ë¬¸ì œì¼ ê°€ëŠ¥ì„±")
            
            # ì‹œì‘ ë‹¨ì–´ë“¤ ë¶„ì„
            if text.strip():
                words = text.strip().split()
                first_words = words[:10]  # ì²˜ìŒ 10ë‹¨ì–´
                logger.info(f"   ğŸ“ ì‹œì‘ 10ë‹¨ì–´: {' '.join(first_words)}")
                
                # ì²« ë²ˆì§¸ ë¬¸ì¥ ì¶”ì¶œ
                first_sentence = text.split('.')[0] if '.' in text else text[:50]
                logger.info(f"   ğŸ“„ ì²« ë¬¸ì¥: '{first_sentence}{'...' if len(text) > 50 and '.' not in text[:50] else ''}'")
            
            logger.info("=" * 60)
            
            logger.info(f"âœ… NeMo ë‹¨ì¼ ì „ì‚¬ ì™„ë£Œ: {len(text)}ì, ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            
            return STTResult(
                text=text,
                language="ko",  # ê¸°ë³¸ ì–¸ì–´
                confidence=0.95,  # NeMoëŠ” ì¼ë°˜ì ìœ¼ë¡œ ë†’ì€ ì‹ ë¢°ë„
                rtf=rtf,  # Real-time factor
                audio_duration=audio_duration,
                segments=self._create_segments(text, audio_duration)
            )
            
        except Exception as e:
            logger.error(f"âŒ NeMo ë‹¨ì¼ ì „ì‚¬ ì‹¤íŒ¨: {e}")
            raise
    
    async def _transcribe_with_chunks(self, audio_array: np.ndarray, audio_duration: float, chunk_duration: float) -> STTResult:
        """VAD ê¸°ë°˜ ì²­í¬ ë‹¨ìœ„ë¡œ ì˜¤ë””ì˜¤ ë¶„í• í•˜ì—¬ ì²˜ë¦¬"""
        print("ğŸš¨ğŸš¨ğŸš¨ _transcribe_with_chunks í•¨ìˆ˜ ì‹œì‘!")
        print(f"ğŸš¨ ì…ë ¥ íŒŒë¼ë¯¸í„° - audio_duration: {audio_duration:.2f}ì´ˆ, chunk_duration: {chunk_duration:.2f}ì´ˆ")
        logger.info("ğŸš¨ğŸš¨ğŸš¨ _transcribe_with_chunks í•¨ìˆ˜ ì‹œì‘!")
        
        try:
            start_time = time.time()
            print(f"ğŸš¨ VAD ê¸°ë°˜ ì²­í¬ ë¶„í•  ì‹œì‘ (ì´ {audio_duration:.1f}ì´ˆ)")
            logger.info(f"ğŸ“¦ VAD ê¸°ë°˜ ì²­í¬ ë¶„í•  ì‹œì‘ (ì´ {audio_duration:.1f}ì´ˆ)")
            
            # VAD ê¸°ë°˜ ìŒì„± êµ¬ê°„ ê°ì§€
            print("ğŸš¨ VAD ìŒì„± êµ¬ê°„ ê°ì§€ ì‹œì‘...")
            voice_segments = await self._detect_voice_segments(audio_array)
            print(f"ğŸš¨ VAD ìŒì„± êµ¬ê°„ ê°ì§€ ì™„ë£Œ! ê°ì§€ëœ êµ¬ê°„ ìˆ˜: {len(voice_segments) if voice_segments else 0}")
            
            if not voice_segments:
                print("ğŸš¨ ìŒì„± êµ¬ê°„ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ!")
                logger.warning("âš ï¸ ìŒì„± êµ¬ê°„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
                return STTResult(
                    text="",
                    language="ko",
                    confidence=0.0,
                    rtf=0.0,
                    audio_duration=audio_duration,
                    segments=[]
                )
            
            logger.info(f"ğŸ™ï¸ {len(voice_segments)}ê°œ ìŒì„± êµ¬ê°„ ê°ì§€ë¨")
            
            # ìŒì„± êµ¬ê°„ì„ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ê·¸ë£¹í™”
            print(f"ğŸš¨ ì²­í¬ ê·¸ë£¹í™” ì‹œì‘! ìŒì„± êµ¬ê°„ ìˆ˜: {len(voice_segments)}ê°œ")
            chunks = []
            current_chunk_segments = []
            current_chunk_duration = 0.0
            is_first_chunk = True
            
            print(f"ğŸš¨ chunk_duration ê°’: {chunk_duration}")
            print(f"ğŸš¨ voice_segments ì²« ë²ˆì§¸ êµ¬ê°„: {voice_segments[0] if voice_segments else 'None'}")
            
            for i, segment in enumerate(voice_segments):
                print(f"ğŸš¨ êµ¬ê°„ {i+1} ì²˜ë¦¬ ì‹œì‘: {segment}")
                
                segment_duration = segment['duration']
                segment_start = segment['start_time']
                segment_end = segment['end_time']
                
                print(f"ğŸš¨ êµ¬ê°„ {i+1} - start: {segment_start:.2f}s, end: {segment_end:.2f}s, duration: {segment_duration:.2f}s")
                logger.info(f"ğŸ”„ êµ¬ê°„ {i+1} ì²˜ë¦¬ ì¤‘: {segment_start:.2f}s~{segment_end:.2f}s (ê¸¸ì´: {segment_duration:.2f}s)")
                
                # ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ê°€ 10ì´ˆë¥¼ ë„˜ëŠ” ê²½ìš° ê°•ì œë¡œ ë¶„í• 
                if segment_duration > chunk_duration:
                    logger.warning(f"âš ï¸ êµ¬ê°„ {i+1}ì´ {chunk_duration}ì´ˆë¥¼ ì´ˆê³¼ ({segment_duration:.2f}s)! ê°•ì œ ë¶„í•  í•„ìš”")
                    
                    # í˜„ì¬ ì²­í¬ ë¨¼ì € ì²˜ë¦¬
                    if current_chunk_segments:
                        logger.info(f"   ğŸ“¦ í˜„ì¬ ì²­í¬ {len(chunks)+1} ì™„ë£Œ (êµ¬ê°„ {len(current_chunk_segments)}ê°œ, ì´ {current_chunk_duration:.2f}s)")
                        chunk_info = self._create_chunk_from_segments(current_chunk_segments, audio_array, is_first_chunk)
                        chunks.append(chunk_info)
                        is_first_chunk = False
                        current_chunk_segments = []
                        current_chunk_duration = 0.0
                    
                    # ê¸´ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ 10ì´ˆ ë‹¨ìœ„ë¡œ ë¶„í• 
                    segment_chunks = self._split_long_segment(segment, chunk_duration, audio_array, is_first_chunk)
                    for seg_chunk in segment_chunks:
                        chunks.append(seg_chunk)
                        is_first_chunk = False
                        logger.info(f"   ğŸ“¦ ë¶„í• ëœ ì²­í¬ {len(chunks)} ì¶”ê°€: {seg_chunk['start_time']:.2f}s~{seg_chunk['end_time']:.2f}s (ê¸¸ì´: {seg_chunk['duration']:.2f}s)")
                    
                    continue
                
                # íŒ¨ë”©ì„ ê³ ë ¤í•œ ì˜ˆìƒ ì²­í¬ ê¸¸ì´ ê³„ì‚°
                estimated_padding = 0.7 if not current_chunk_segments else 0.3  # ì²« ë²ˆì§¸ ì²­í¬ ì—¬ë¶€ì— ë”°ë¼
                estimated_chunk_duration = current_chunk_duration + segment_duration + estimated_padding
                
                # í˜„ì¬ ì²­í¬ì— ì¶”ê°€í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸ (íŒ¨ë”© ê³ ë ¤)
                if estimated_chunk_duration <= chunk_duration:
                    current_chunk_segments.append(segment)
                    current_chunk_duration += segment_duration
                    logger.info(f"   âœ… í˜„ì¬ ì²­í¬ì— ì¶”ê°€ (ëˆ„ì  ê¸¸ì´: {current_chunk_duration:.2f}s, íŒ¨ë”© í¬í•¨ ì˜ˆìƒ: {estimated_chunk_duration:.2f}s)")
                else:
                    # í˜„ì¬ ì²­í¬ ì™„ë£Œ
                    if current_chunk_segments:
                        logger.info(f"   ğŸ“¦ ì²­í¬ {len(chunks)+1} ì™„ë£Œ (êµ¬ê°„ {len(current_chunk_segments)}ê°œ, ì´ {current_chunk_duration:.2f}s)")
                        chunk_info = self._create_chunk_from_segments(current_chunk_segments, audio_array, is_first_chunk)
                        chunks.append(chunk_info)
                        is_first_chunk = False
                    
                    # ìƒˆ ì²­í¬ ì‹œì‘
                    current_chunk_segments = [segment]
                    current_chunk_duration = segment_duration
                    logger.info(f"   ğŸ†• ìƒˆ ì²­í¬ {len(chunks)+1} ì‹œì‘ (ê¸¸ì´: {current_chunk_duration:.2f}s)")
            
            # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
            if current_chunk_segments:
                print(f"ğŸš¨ ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬ ì¤‘...")
                logger.info(f"   ğŸ“¦ ë§ˆì§€ë§‰ ì²­í¬ {len(chunks)+1} ì™„ë£Œ (êµ¬ê°„ {len(current_chunk_segments)}ê°œ, ì´ {current_chunk_duration:.2f}s)")
                chunk_info = self._create_chunk_from_segments(current_chunk_segments, audio_array, is_first_chunk)
                chunks.append(chunk_info)
            
            print(f"ğŸš¨ ì´ ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")
            print(f"ğŸš¨ ì²­í¬ ì „ì‚¬ ì²˜ë¦¬ ì‹œì‘...")
            
            all_texts = []
            total_confidence = 0.0
            
            for i, chunk_info in enumerate(chunks):
                print(f"ğŸš¨ ì²­í¬ {i+1}/{len(chunks)} ì „ì‚¬ ì‹œì‘!")
                
                chunk_audio = chunk_info['audio']
                chunk_start = chunk_info['start_time']
                chunk_end = chunk_info['end_time']
                chunk_duration = chunk_info['duration']
                
                print(f"ğŸš¨ ì²­í¬ {i+1} ì •ë³´ - start: {chunk_start:.1f}s, end: {chunk_end:.1f}s, duration: {chunk_duration:.2f}s")
                logger.info(f"ğŸ”„ ì²­í¬ {i+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘ ({chunk_start:.1f}s-{chunk_end:.1f}s, ê¸¸ì´: {chunk_duration:.2f}s)")

                
                try:
                    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
                    import torch
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    
                    # ì²­í¬ ì „ì‚¬ (íŒŒì¼ ê¸°ë°˜)
                    try:
                        import tempfile
                        import soundfile as sf
                        import os
                        from pathlib import Path
                        
                        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_file:
                            temp_path = temp_file.name
                        
                        # WAV íŒŒì¼ë¡œ ì €ì¥
                        sf.write(temp_path, chunk_audio, 16000, subtype='PCM_16')
                        
                        try:
                            # íŒŒì¼ ê²½ë¡œë¥¼ ì‚¬ìš©í•´ì„œ transcribe
                            chunk_result = self.model.transcribe([temp_path])
                        finally:
                            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                            if os.path.exists(temp_path):
                                os.unlink(temp_path)
                                
                    except Exception as chunk_error:
                        logger.warning(f"âš ï¸ ì²­í¬ {i+1} ì „ì‚¬ ì‹¤íŒ¨: {chunk_error}")
                        chunk_result = [""]
                    
                    chunk_text = self._extract_text_from_result(chunk_result)
                    
                    # ğŸ¯ ì²­í¬ë³„ í…ìŠ¤íŠ¸ ì¦‰ì‹œ ì¶œë ¥ (ì½˜ì†”)
                    print("=" * 80)
                    print(f"ğŸ¯ ì²­í¬ {i+1}/{len(chunks)} ì „ì‚¬ ì™„ë£Œ!")
                    print(f"ğŸ“ ì‹œê°„: {chunk_start:.2f}s ~ {chunk_end:.2f}s ({chunk_duration:.2f}ì´ˆ)")
                    if chunk_text.strip():
                        print(f"ğŸ“ í…ìŠ¤íŠ¸: '{chunk_text}'")
                        print(f"ğŸ“Š ê¸¸ì´: {len(chunk_text)}ì, ë‹¨ì–´ ìˆ˜: {len(chunk_text.split())}ê°œ")
                        if "ì½”ë¡œë‚˜" in chunk_text:
                            print(f"   âœ… 'ì½”ë¡œë‚˜' í‚¤ì›Œë“œ ë°œê²¬!")
                    else:
                        print(f"âšª ë¬´ìŒ êµ¬ê°„ - í…ìŠ¤íŠ¸ ì—†ìŒ")
                    print("=" * 80)
                    
                    # ğŸ” ì²­í¬ë³„ í…ìŠ¤íŠ¸ ê²°ê³¼ ìƒì„¸ ë””ë²„ê¹…
                    logger.info("=" * 80)
                    logger.info(f"ğŸ” ì²­í¬ {i+1}/{len(chunks)} ì „ì‚¬ ê²°ê³¼ ìƒì„¸ ë¶„ì„")
                    logger.info("=" * 80)
                    logger.info(f"ğŸ“ ì²­í¬ ì •ë³´:")
                    logger.info(f"   â€¢ ì‹œê°„ ë²”ìœ„: {chunk_start:.2f}s ~ {chunk_end:.2f}s")
                    logger.info(f"   â€¢ ì²­í¬ ê¸¸ì´: {chunk_duration:.2f}ì´ˆ")
                    logger.info(f"   â€¢ ì˜¤ë””ì˜¤ ìƒ˜í”Œ: {len(chunk_audio):,}ê°œ")
                    
                    # ì›ì‹œ ê²°ê³¼ ë¶„ì„
                    logger.info(f"ğŸ¤– NeMo ì›ì‹œ ê²°ê³¼:")
                    logger.info(f"   â€¢ ê²°ê³¼ íƒ€ì…: {type(chunk_result)}")
                    if hasattr(chunk_result, '__len__'):
                        logger.info(f"   â€¢ ê²°ê³¼ ê¸¸ì´: {len(chunk_result)}")
                    if isinstance(chunk_result, (list, tuple)) and len(chunk_result) > 0:
                        logger.info(f"   â€¢ ì²« ë²ˆì§¸ ìš”ì†Œ íƒ€ì…: {type(chunk_result[0])}")
                        logger.info(f"   â€¢ ì²« ë²ˆì§¸ ìš”ì†Œ: {chunk_result[0]}")
                    
                    # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¶„ì„
                    logger.info(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸:")
                    logger.info(f"   â€¢ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(chunk_text)}ì")
                    logger.info(f"   â€¢ ë¹ˆ í…ìŠ¤íŠ¸ ì—¬ë¶€: {'ì˜ˆ' if not chunk_text.strip() else 'ì•„ë‹ˆì˜¤'}")
                    
                    if chunk_text.strip():
                        logger.info(f"   â€¢ ì „ì²´ í…ìŠ¤íŠ¸: '{chunk_text}'")
                        
                        # ë‹¨ì–´ ë¶„ì„
                        words = chunk_text.strip().split()
                        logger.info(f"   â€¢ ë‹¨ì–´ ìˆ˜: {len(words)}ê°œ")
                        if len(words) > 0:
                            logger.info(f"   â€¢ ì²« ë²ˆì§¸ ë‹¨ì–´: '{words[0]}'")
                            logger.info(f"   â€¢ ë§ˆì§€ë§‰ ë‹¨ì–´: '{words[-1]}'")
                        
                        # íŠ¹ì • í‚¤ì›Œë“œ ì²´í¬
                        if "ì½”ë¡œë‚˜" in chunk_text:
                            logger.info(f"   âœ… 'ì½”ë¡œë‚˜' í‚¤ì›Œë“œ ë°œê²¬!")
                        
                        # ë¬¸ì¥ ë¶„ì„
                        sentences = [s.strip() for s in chunk_text.split('.') if s.strip()]
                        logger.info(f"   â€¢ ë¬¸ì¥ ìˆ˜: {len(sentences)}ê°œ")
                        for j, sentence in enumerate(sentences[:3]):  # ì²˜ìŒ 3ë¬¸ì¥ë§Œ
                            logger.info(f"     ë¬¸ì¥ {j+1}: '{sentence}'")
                    else:
                        logger.info(f"   âšª ë¬´ìŒ êµ¬ê°„ - í…ìŠ¤íŠ¸ ì—†ìŒ")
                    
                    logger.info("=" * 80)
                    
                    if chunk_text.strip():
                        all_texts.append(chunk_text.strip())
                        total_confidence += 0.95  # ê° ì²­í¬ì˜ ê¸°ë³¸ ì‹ ë¢°ë„
                        logger.info(f"âœ… ì²­í¬ {i+1} ì²˜ë¦¬ ì™„ë£Œ: {len(chunk_text)}ì ì¶”ê°€ë¨")
                    else:
                        logger.info(f"âšª ì²­í¬ {i+1}: ë¬´ìŒ êµ¬ê°„ìœ¼ë¡œ ê±´ë„ˆëœ€")
                
                except Exception as chunk_error:
                    import traceback
                    logger.warning(f"âš ï¸ ì²­í¬ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {chunk_error}")
                    logger.warning(f"âš ï¸ ì²­í¬ {i+1} ì—ëŸ¬ ìƒì„¸: {traceback.format_exc()}")
                    # ì²­í¬ ì‹¤íŒ¨ ì‹œ ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰
                    continue
            
            # ìµœì¢… ê²°ê³¼ ì¡°í•©
            final_text = " ".join(all_texts)
            avg_confidence = total_confidence / max(len(all_texts), 1) if all_texts else 0.0
            processing_time = time.time() - start_time
            rtf = processing_time / audio_duration if audio_duration > 0 else 0.0
            
            # ğŸ¯ ìµœì¢… ê²°ê³¼ ì¦‰ì‹œ ì¶œë ¥ (ì½˜ì†”)
            print("=" * 100)
            print("ğŸ¯ ì²­í¬ ì „ì‚¬ ì™„ë£Œ! ìµœì¢… ê²°ê³¼ ìš”ì•½")
            print("=" * 100)
            print(f"ğŸ“Š ì²˜ë¦¬ í†µê³„: {len(chunks)}ê°œ ì²­í¬, {len(all_texts)}ê°œ í…ìŠ¤íŠ¸, {processing_time:.2f}ì´ˆ")
            print(f"ğŸ“ ê°œë³„ ì²­í¬ ê²°ê³¼:")
            for i, text in enumerate(all_texts):
                print(f"   ì²­í¬ {i+1}: '{text}'")
            print(f"ğŸ”— ìµœì¢… ë³‘í•© í…ìŠ¤íŠ¸: '{final_text}'")
            print(f"ğŸ“Š ì´ {len(final_text)}ì, {len(final_text.split())}ê°œ ë‹¨ì–´")
            if "ì½”ë¡œë‚˜" in final_text:
                print(f"âœ… 'ì½”ë¡œë‚˜' í‚¤ì›Œë“œ ìµœì¢… í™•ì¸ë¨!")
            else:
                print(f"âš ï¸ 'ì½”ë¡œë‚˜' í‚¤ì›Œë“œ ìµœì¢… ê²°ê³¼ì—ì„œ ëˆ„ë½")
            print("=" * 100)
            
            # ğŸ” ìµœì¢… ê²°ê³¼ ìƒì„¸ ë¶„ì„
            logger.info("=" * 100)
            logger.info("ğŸ¯ ìµœì¢… ì „ì‚¬ ê²°ê³¼ ì¢…í•© ë¶„ì„")
            logger.info("=" * 100)
            logger.info(f"ğŸ“Š ì²˜ë¦¬ í†µê³„:")
            logger.info(f"   â€¢ ì²˜ë¦¬ëœ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")
            logger.info(f"   â€¢ í…ìŠ¤íŠ¸ê°€ ìˆëŠ” ì²­í¬: {len(all_texts)}ê°œ")
            logger.info(f"   â€¢ ë¬´ìŒ ì²­í¬: {len(chunks) - len(all_texts)}ê°œ")
            logger.info(f"   â€¢ ì´ ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            logger.info(f"   â€¢ RTF (Real-time Factor): {rtf:.3f}")
            logger.info(f"   â€¢ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")
            
            logger.info(f"ğŸ“ ê°œë³„ ì²­í¬ í…ìŠ¤íŠ¸:")
            for i, text in enumerate(all_texts):
                logger.info(f"   ì²­í¬ {i+1}: '{text}'")
            
            logger.info(f"ğŸ”— ìµœì¢… ë³‘í•© í…ìŠ¤íŠ¸:")
            logger.info(f"   â€¢ ì´ ê¸¸ì´: {len(final_text)}ì")
            logger.info(f"   â€¢ ë‹¨ì–´ ìˆ˜: {len(final_text.split())}ê°œ")
            logger.info(f"   â€¢ ì „ì²´ í…ìŠ¤íŠ¸: '{final_text}'")
            
            # íŠ¹ì • í‚¤ì›Œë“œ ìµœì¢… ì²´í¬
            if "ì½”ë¡œë‚˜" in final_text:
                logger.info(f"   âœ… ìµœì¢… ê²°ê³¼ì—ì„œ 'ì½”ë¡œë‚˜' í‚¤ì›Œë“œ í™•ì¸ë¨!")
            else:
                logger.info(f"   âš ï¸ ìµœì¢… ê²°ê³¼ì—ì„œ 'ì½”ë¡œë‚˜' í‚¤ì›Œë“œ ëˆ„ë½")
            
            logger.info("=" * 100)
            
            logger.info(f"âœ… VAD ê¸°ë°˜ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ: ì´ {len(final_text)}ì, ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ")
            
            return STTResult(
                text=final_text,
                language="ko",  # ê¸°ë³¸ ì–¸ì–´
                confidence=avg_confidence,
                rtf=rtf,  # Real-time factor
                audio_duration=audio_duration,
                segments=self._create_segments(final_text, audio_duration)
            )
            
        except Exception as e:
            print(f"ğŸš¨ğŸš¨ğŸš¨ _transcribe_with_chunks ì—ëŸ¬: {e}")
            logger.error(f"âŒ NeMo VAD ì²­í¬ ì „ì‚¬ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ğŸš¨ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            logger.error(f"âŒ ìƒì„¸ ì—ëŸ¬: {traceback.format_exc()}")
            raise
    
    async def _detect_voice_segments(self, audio_array: np.ndarray) -> List[Dict]:
        """VADë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± êµ¬ê°„ ê°ì§€"""
        try:
            # Silero VAD ì‚¬ìš©
            logger.info("ğŸ™ï¸ Silero VADë¡œ ìŒì„± êµ¬ê°„ ê°ì§€ ì¤‘...")
            
            try:
                import torch
                
                # Silero VAD ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ ë¡œë“œ)
                if not hasattr(self, '_vad_model'):
                    self._vad_model, utils = torch.hub.load(
                        repo_or_dir='snakers4/silero-vad',
                        model='silero_vad',
                        force_reload=False,
                        onnx=False
                    )
                    self._vad_get_speech_timestamps = utils[0]
                    logger.info("ğŸ“¦ Silero VAD ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
                # ì˜¤ë””ì˜¤ë¥¼ torch tensorë¡œ ë³€í™˜
                audio_tensor = torch.tensor(audio_array).float()
                
                # ìŒì„± êµ¬ê°„ ê°ì§€ (16kHz ê°€ì •) - ë³´ìˆ˜ì  ì„¤ì •ìœ¼ë¡œ ì¡°ì •
                speech_timestamps = self._vad_get_speech_timestamps(
                    audio_tensor, 
                    self._vad_model,
                    sampling_rate=16000,
                    threshold=0.4,  # ìŒì„± ê°ì§€ ì„ê³„ê°’ (0.2 â†’ 0.4ë¡œ ì¦ê°€, ëœ ë¯¼ê°)
                    min_speech_duration_ms=200,  # ìµœì†Œ ìŒì„± ê¸¸ì´ ìœ ì§€
                    min_silence_duration_ms=100,  # ìµœì†Œ ë¬´ìŒ ê¸¸ì´ ìœ ì§€
                    window_size_samples=512,  # ìœˆë„ìš° í¬ê¸° ìœ ì§€
                    speech_pad_ms=100  # ìŒì„± êµ¬ê°„ íŒ¨ë”© (300ms â†’ 100msë¡œ ê°ì†Œ)
                )
                
                # ê²°ê³¼ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë³€í™˜
                voice_segments = []
                for segment in speech_timestamps:
                    start_sample = segment['start']
                    end_sample = segment['end']
                    start_time = start_sample / 16000.0
                    end_time = end_sample / 16000.0
                    
                    voice_segments.append({
                        'start_time': start_time,
                        'end_time': end_time,
                        'start_sample': start_sample,
                        'end_sample': end_sample,
                        'duration': end_time - start_time
                    })
                
                logger.info(f"ğŸ™ï¸ Silero VAD: {len(voice_segments)}ê°œ ìŒì„± êµ¬ê°„ ê°ì§€")
                
                # ğŸ” VAD êµ¬ê°„ ìƒì„¸ ë””ë²„ê¹…
                logger.info("=" * 60)
                logger.info("ğŸ” VAD ìŒì„± êµ¬ê°„ ìƒì„¸ ë¶„ì„")
                logger.info("=" * 60)
                total_speech_duration = 0.0
                for i, segment in enumerate(voice_segments):
                    start_time = segment['start_time']
                    end_time = segment['end_time']
                    duration = segment['duration']
                    total_speech_duration += duration
                    
                    logger.info(f"ğŸ“ êµ¬ê°„ {i+1:2d}: {start_time:6.2f}s ~ {end_time:6.2f}s (ê¸¸ì´: {duration:5.2f}s)")
                    
                    # êµ¬ê°„ ë‚´ ì˜¤ë””ì˜¤ ìƒ˜í”Œ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ ëª‡ ê¸€ìë§Œ)
                    start_sample = int(start_time * 16000)
                    end_sample = int(end_time * 16000)
                    segment_audio = audio_array[start_sample:end_sample]
                    
                    # ì—ë„ˆì§€ ë ˆë²¨ ê³„ì‚°
                    energy = np.mean(segment_audio ** 2) if len(segment_audio) > 0 else 0.0
                    max_amplitude = np.max(np.abs(segment_audio)) if len(segment_audio) > 0 else 0.0
                    
                    logger.info(f"   ğŸ”Š ì—ë„ˆì§€: {energy:.6f}, ìµœëŒ€ ì§„í­: {max_amplitude:.3f}")
                
                logger.info("-" * 60)
                logger.info(f"ğŸ“Š VAD ìš”ì•½:")
                logger.info(f"   â€¢ ì „ì²´ ì˜¤ë””ì˜¤ ê¸¸ì´: {len(audio_array) / 16000.0:.2f}ì´ˆ")
                logger.info(f"   â€¢ ì´ ìŒì„± êµ¬ê°„: {len(voice_segments)}ê°œ")
                logger.info(f"   â€¢ ì´ ìŒì„± ê¸¸ì´: {total_speech_duration:.2f}ì´ˆ")
                logger.info(f"   â€¢ ìŒì„± ë¹„ìœ¨: {total_speech_duration / (len(audio_array) / 16000.0) * 100:.1f}%")
                
                # ë¬´ìŒ êµ¬ê°„ ë¶„ì„
                if len(voice_segments) > 1:
                    logger.info(f"ğŸ”‡ ë¬´ìŒ êµ¬ê°„ ë¶„ì„:")
                    for i in range(len(voice_segments) - 1):
                        silence_start = voice_segments[i]['end_time']
                        silence_end = voice_segments[i + 1]['start_time']
                        silence_duration = silence_end - silence_start
                        logger.info(f"   ë¬´ìŒ {i+1}: {silence_start:.2f}s ~ {silence_end:.2f}s (ê¸¸ì´: {silence_duration:.2f}s)")
                
                logger.info("=" * 60)
                
                return voice_segments
                
            except Exception as silero_error:
                logger.warning(f"âš ï¸ Silero VAD ì‹¤íŒ¨, ê°„ë‹¨í•œ ì—ë„ˆì§€ ê¸°ë°˜ VAD ì‚¬ìš©: {silero_error}")
                return self._simple_energy_vad(audio_array)
                
        except Exception as e:
            logger.error(f"âŒ VAD ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            # VAD ì‹¤íŒ¨ ì‹œ ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì²˜ë¦¬
            return [{
                'start_time': 0.0,
                'end_time': len(audio_array) / 16000.0,
                'start_sample': 0,
                'end_sample': len(audio_array),
                'duration': len(audio_array) / 16000.0
            }]
    
    def _simple_energy_vad(self, audio_array: np.ndarray) -> List[Dict]:
        """ê°„ë‹¨í•œ ì—ë„ˆì§€ ê¸°ë°˜ VAD (Silero VAD ì‹¤íŒ¨ ì‹œ ëŒ€ì•ˆ)"""
        try:
            # í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì—ë„ˆì§€ ê³„ì‚°
            frame_length = int(0.025 * 16000)  # 25ms í”„ë ˆì„
            frame_step = int(0.010 * 16000)    # 10ms ìŠ¤í…
            
            frames = []
            for i in range(0, len(audio_array) - frame_length, frame_step):
                frame = audio_array[i:i + frame_length]
                energy = np.sum(frame ** 2)
                frames.append(energy)
            
            # ì—ë„ˆì§€ ì„ê³„ê°’ ì„¤ì • (ì ì ˆí•œ ë¯¼ê°ë„ë¡œ ì¡°ì •)
            threshold = np.percentile(frames, 90) * 0.05  # 85% â†’ 90%, 1% â†’ 5%ë¡œ ì¡°ì •
            
            # ìŒì„± êµ¬ê°„ ê°ì§€
            voice_segments = []
            in_speech = False
            start_frame = 0
            
            for i, energy in enumerate(frames):
                if energy > threshold and not in_speech:
                    # ìŒì„± ì‹œì‘
                    in_speech = True
                    start_frame = i
                elif energy <= threshold and in_speech:
                    # ìŒì„± ì¢…ë£Œ
                    in_speech = False
                    
                    start_sample = start_frame * frame_step
                    end_sample = i * frame_step
                    start_time = start_sample / 16000.0
                    end_time = end_sample / 16000.0
                    
                    # ìµœì†Œ ê¸¸ì´ ì²´í¬ (0.1ì´ˆ ì´ìƒìœ¼ë¡œ ë” ì™„í™”)
                    if end_time - start_time >= 0.1:
                        voice_segments.append({
                            'start_time': start_time,
                            'end_time': end_time,
                            'start_sample': start_sample,
                            'end_sample': end_sample,
                            'duration': end_time - start_time
                        })
            
            # ë§ˆì§€ë§‰ êµ¬ê°„ ì²˜ë¦¬
            if in_speech:
                start_sample = start_frame * frame_step
                end_sample = len(audio_array)
                start_time = start_sample / 16000.0
                end_time = end_sample / 16000.0
                
                if end_time - start_time >= 0.1:
                    voice_segments.append({
                        'start_time': start_time,
                        'end_time': end_time,
                        'start_sample': start_sample,
                        'end_sample': end_sample,
                        'duration': end_time - start_time
                    })
            
            logger.info(f"ğŸ”Š ì—ë„ˆì§€ ê¸°ë°˜ VAD: {len(voice_segments)}ê°œ ìŒì„± êµ¬ê°„ ê°ì§€")
            return voice_segments
            
        except Exception as e:
            logger.error(f"âŒ ì—ë„ˆì§€ ê¸°ë°˜ VAD ì‹¤íŒ¨: {e}")
            # ìµœí›„ì˜ ìˆ˜ë‹¨: ì „ì²´ ì˜¤ë””ì˜¤ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ì²˜ë¦¬
            return [{
                'start_time': 0.0,
                'end_time': len(audio_array) / 16000.0,
                'start_sample': 0,
                'end_sample': len(audio_array),
                'duration': len(audio_array) / 16000.0
            }]
    
    def _group_segments_into_chunks(self, voice_segments: List[Dict], audio_array: np.ndarray, max_chunk_duration: float = 10.0) -> List[Dict]:
        """ìŒì„± êµ¬ê°„ë“¤ì„ ì ì ˆí•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ê·¸ë£¹í™” (NeMo ìµœì í™”: 10ì´ˆ ì œí•œ)"""
        logger.info("=" * 60)
        logger.info("ğŸ” ì²­í¬ ê·¸ë£¹í™” ê³¼ì • ìƒì„¸ ë¶„ì„ (NeMo 10ì´ˆ ì œí•œ)")
        logger.info("=" * 60)
        logger.info(f"ğŸ“¦ ìµœëŒ€ ì²­í¬ ê¸¸ì´: {max_chunk_duration}ì´ˆ (NeMo ê¶Œì¥: â‰¤10ì´ˆ)")
        logger.info(f"ğŸ“ ì²˜ë¦¬í•  ìŒì„± êµ¬ê°„: {len(voice_segments)}ê°œ")
        
        chunks = []
        current_chunk_segments = []
        current_chunk_duration = 0.0
        is_first_chunk = True
        
        for i, segment in enumerate(voice_segments):
            segment_duration = segment['duration']
            segment_start = segment['start_time']
            segment_end = segment['end_time']
            
            logger.info(f"ğŸ”„ êµ¬ê°„ {i+1} ì²˜ë¦¬ ì¤‘: {segment_start:.2f}s~{segment_end:.2f}s (ê¸¸ì´: {segment_duration:.2f}s)")
            
            # ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ê°€ 15ì´ˆë¥¼ ë„˜ëŠ” ê²½ìš° ê°•ì œë¡œ ë¶„í• 
            if segment_duration > max_chunk_duration:
                logger.warning(f"âš ï¸ êµ¬ê°„ {i+1}ì´ {max_chunk_duration}ì´ˆë¥¼ ì´ˆê³¼ ({segment_duration:.2f}s)! ê°•ì œ ë¶„í•  í•„ìš”")
                
                # í˜„ì¬ ì²­í¬ ë¨¼ì € ì²˜ë¦¬
                if current_chunk_segments:
                    logger.info(f"   ğŸ“¦ í˜„ì¬ ì²­í¬ {len(chunks)+1} ì™„ë£Œ (êµ¬ê°„ {len(current_chunk_segments)}ê°œ, ì´ {current_chunk_duration:.2f}s)")
                    chunk_info = self._create_chunk_from_segments(current_chunk_segments, audio_array, is_first_chunk)
                    chunks.append(chunk_info)
                    is_first_chunk = False
                    current_chunk_segments = []
                    current_chunk_duration = 0.0
                
                # ê¸´ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ 15ì´ˆ ë‹¨ìœ„ë¡œ ë¶„í• 
                segment_chunks = self._split_long_segment(segment, max_chunk_duration, audio_array, is_first_chunk)
                for seg_chunk in segment_chunks:
                    chunks.append(seg_chunk)
                    is_first_chunk = False
                    logger.info(f"   ğŸ“¦ ë¶„í• ëœ ì²­í¬ {len(chunks)} ì¶”ê°€: {seg_chunk['start_time']:.2f}s~{seg_chunk['end_time']:.2f}s (ê¸¸ì´: {seg_chunk['duration']:.2f}s)")
                
                continue
            
            # íŒ¨ë”©ì„ ê³ ë ¤í•œ ì˜ˆìƒ ì²­í¬ ê¸¸ì´ ê³„ì‚°
            estimated_padding = 0.7 if not current_chunk_segments else 0.3  # ì²« ë²ˆì§¸ ì²­í¬ ì—¬ë¶€ì— ë”°ë¼
            estimated_chunk_duration = current_chunk_duration + segment_duration + estimated_padding
            
            # í˜„ì¬ ì²­í¬ì— ì¶”ê°€í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸ (íŒ¨ë”© ê³ ë ¤)
            if estimated_chunk_duration <= max_chunk_duration:
                current_chunk_segments.append(segment)
                current_chunk_duration += segment_duration
                logger.info(f"   âœ… í˜„ì¬ ì²­í¬ì— ì¶”ê°€ (ëˆ„ì  ê¸¸ì´: {current_chunk_duration:.2f}s, íŒ¨ë”© í¬í•¨ ì˜ˆìƒ: {estimated_chunk_duration:.2f}s)")
            else:
                # í˜„ì¬ ì²­í¬ ì™„ë£Œ
                if current_chunk_segments:
                    logger.info(f"   ğŸ“¦ ì²­í¬ {len(chunks)+1} ì™„ë£Œ (êµ¬ê°„ {len(current_chunk_segments)}ê°œ, ì´ {current_chunk_duration:.2f}s)")
                    chunk_info = self._create_chunk_from_segments(current_chunk_segments, audio_array, is_first_chunk)
                    chunks.append(chunk_info)
                    is_first_chunk = False
                
                # ìƒˆ ì²­í¬ ì‹œì‘
                current_chunk_segments = [segment]
                current_chunk_duration = segment_duration
                logger.info(f"   ğŸ†• ìƒˆ ì²­í¬ {len(chunks)+1} ì‹œì‘ (ê¸¸ì´: {current_chunk_duration:.2f}s)")
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
        if current_chunk_segments:
            logger.info(f"   ğŸ“¦ ë§ˆì§€ë§‰ ì²­í¬ {len(chunks)+1} ì™„ë£Œ (êµ¬ê°„ {len(current_chunk_segments)}ê°œ, ì´ {current_chunk_duration:.2f}s)")
            chunk_info = self._create_chunk_from_segments(current_chunk_segments, audio_array, is_first_chunk)
            chunks.append(chunk_info)
        
        logger.info("-" * 60)
        logger.info(f"ğŸ“Š ì²­í¬ ê·¸ë£¹í™” ìš”ì•½:")
        logger.info(f"   â€¢ ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")
        
        # 10ì´ˆ ì´ˆê³¼ ì²­í¬ ì²´í¬
        over_limit_chunks = []
        for i, chunk in enumerate(chunks):
            chunk_duration = chunk['duration']
            logger.info(f"   â€¢ ì²­í¬ {i+1}: {chunk['start_time']:.2f}s~{chunk['end_time']:.2f}s (ê¸¸ì´: {chunk_duration:.2f}s)")
            
            if chunk_duration > 10.0:
                over_limit_chunks.append((i+1, chunk_duration))
                logger.warning(f"     âš ï¸ ì²­í¬ {i+1}ì´ 10ì´ˆ ì´ˆê³¼! ({chunk_duration:.2f}s)")
        
        if over_limit_chunks:
            logger.error(f"âŒ {len(over_limit_chunks)}ê°œ ì²­í¬ê°€ 10ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤!")
            for chunk_num, duration in over_limit_chunks:
                logger.error(f"   ì²­í¬ {chunk_num}: {duration:.2f}s")
        else:
            logger.info(f"âœ… ëª¨ë“  ì²­í¬ê°€ 10ì´ˆ ì´í•˜ë¡œ ì œí•œë¨")
        
        logger.info("=" * 60)
        
        return chunks
    
    def _split_long_segment(self, segment: Dict, max_duration: float, audio_array: np.ndarray, is_first_chunk: bool) -> List[Dict]:
        """10ì´ˆë¥¼ ë„˜ëŠ” ê¸´ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë” ì‘ì€ ì²­í¬ë¡œ ë¶„í• """
        logger.info(f"ğŸ”§ ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì‹œì‘: {segment['start_time']:.2f}s~{segment['end_time']:.2f}s (ê¸¸ì´: {segment['duration']:.2f}s)")
        
        segment_start = segment['start_time']
        segment_end = segment['end_time']
        segment_duration = segment['duration']
        
        # ë¶„í• í•  ì²­í¬ ìˆ˜ ê³„ì‚°
        num_chunks = int(np.ceil(segment_duration / max_duration))
        chunk_duration = segment_duration / num_chunks
        
        logger.info(f"   ğŸ“Š ë¶„í•  ê³„íš: {num_chunks}ê°œ ì²­í¬, ê° ì²­í¬ ì•½ {chunk_duration:.2f}ì´ˆ")
        
        chunks = []
        current_first_chunk = is_first_chunk
        
        for i in range(num_chunks):
            # ì²­í¬ ì‹œê°„ ë²”ìœ„ ê³„ì‚°
            chunk_start_time = segment_start + (i * chunk_duration)
            chunk_end_time = min(segment_end, segment_start + ((i + 1) * chunk_duration))
            
            # ë§ˆì§€ë§‰ ì²­í¬ëŠ” ë‚¨ì€ ë¶€ë¶„ì„ ëª¨ë‘ í¬í•¨
            if i == num_chunks - 1:
                chunk_end_time = segment_end
            
            logger.info(f"   ğŸ”¸ ë¶„í•  ì²­í¬ {i+1}: {chunk_start_time:.2f}s~{chunk_end_time:.2f}s")
            
            # íŒ¨ë”© ì ìš©
            if current_first_chunk:
                # ì²« ë²ˆì§¸ ì²­í¬ëŠ” 0ì´ˆë¶€í„° ì‹œì‘
                padded_start_time = 0.0
                actual_start_padding = chunk_start_time - padded_start_time
            else:
                # ë‚˜ë¨¸ì§€ ì²­í¬ëŠ” 0.3ì´ˆ íŒ¨ë”©
                padded_start_time = max(0.0, chunk_start_time - 0.3)
                actual_start_padding = chunk_start_time - padded_start_time
            
            # ë íŒ¨ë”© 0.7ì´ˆ
            max_end_time = len(audio_array) / 16000.0
            padded_end_time = min(max_end_time, chunk_end_time + 0.7)
            actual_end_padding = padded_end_time - chunk_end_time
            
            # ìƒ˜í”Œ ì¸ë±ìŠ¤ ê³„ì‚°
            chunk_start_sample = int(padded_start_time * 16000)
            chunk_end_sample = int(padded_end_time * 16000)
            chunk_end_sample = min(chunk_end_sample, len(audio_array))
            
            # ì˜¤ë””ì˜¤ ì¶”ì¶œ
            chunk_audio = audio_array[chunk_start_sample:chunk_end_sample]
            final_duration = len(chunk_audio) / 16000.0
            
            # ì²­í¬ ì •ë³´ ìƒì„±
            chunk_info = {
                'audio': chunk_audio,
                'start_time': padded_start_time,
                'end_time': padded_end_time,
                'original_start_time': chunk_start_time,
                'original_end_time': chunk_end_time,
                'segments': [{
                    'start_time': chunk_start_time,
                    'end_time': chunk_end_time,
                    'duration': chunk_end_time - chunk_start_time,
                    'start_sample': int(chunk_start_time * 16000),
                    'end_sample': int(chunk_end_time * 16000)
                }],
                'duration': final_duration,
                'start_padding': actual_start_padding,
                'end_padding': actual_end_padding,
                'overlap_start': actual_start_padding,
                'overlap_end': actual_end_padding,
                'split_from_long_segment': True  # ë¶„í• ëœ ì²­í¬ì„ì„ í‘œì‹œ
            }
            
            chunks.append(chunk_info)
            current_first_chunk = False
            
            logger.info(f"     âœ… ë¶„í•  ì²­í¬ {i+1} ìƒì„±: {padded_start_time:.2f}s~{padded_end_time:.2f}s (ì‹¤ì œ ê¸¸ì´: {final_duration:.2f}s)")
        
        logger.info(f"ğŸ”§ ê¸´ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
        return chunks
    
    def _create_chunk_from_segments(self, segments: List[Dict], audio_array: np.ndarray, is_first_chunk: bool = False) -> Dict:
        """ì„¸ê·¸ë¨¼íŠ¸ë“¤ë¡œë¶€í„° ì²­í¬ ìƒì„± (ë¬´ìŒ êµ¬ê°„ í¬í•¨, íŒ¨ë”© ì¶”ê°€, ì˜¤ë²„ë© ì²˜ë¦¬)"""
        if not segments:
            return None
        
        logger.info("ğŸ” ì²­í¬ ìƒì„± ìƒì„¸ ê³¼ì •:")
        logger.info(f"   ğŸ“ í¬í•¨ëœ ìŒì„± êµ¬ê°„: {len(segments)}ê°œ")
        
        # ì²­í¬ì˜ ì‹œì‘ê³¼ ë ì‹œê°„
        chunk_start_time = segments[0]['start_time']
        chunk_end_time = segments[-1]['end_time']
        original_chunk_duration = chunk_end_time - chunk_start_time
        
        logger.info(f"   ğŸ“ ì›ë³¸ ì²­í¬ ë²”ìœ„: {chunk_start_time:.2f}s~{chunk_end_time:.2f}s (ê¸¸ì´: {original_chunk_duration:.2f}s)")
        
        # íŒ¨ë”© ë° ì˜¤ë²„ë© ì¶”ê°€
        if is_first_chunk:
            # ì²« ë²ˆì§¸ ì²­í¬ëŠ” í•­ìƒ 0ì´ˆë¶€í„° ì‹œì‘ (ì‹œì‘ ë¶€ë¶„ ì†ì‹¤ ë°©ì§€)
            padded_start_time = 0.0
            actual_start_padding = chunk_start_time - padded_start_time
            logger.info(f"   ğŸ¯ ì²« ë²ˆì§¸ ì²­í¬: 0ì´ˆë¶€í„° ì‹œì‘ (íŒ¨ë”©: {actual_start_padding:.2f}s)")
        else:
            # ë‚˜ë¨¸ì§€ ì²­í¬ëŠ” ì•ìª½ì— 0.3ì´ˆ íŒ¨ë”©
            start_padding_seconds = 0.3
            padded_start_time = max(0.0, chunk_start_time - start_padding_seconds)
            actual_start_padding = chunk_start_time - padded_start_time
            logger.info(f"   âª ì‹œì‘ íŒ¨ë”©: {actual_start_padding:.2f}s")
        
        # ë ë¶€ë¶„ì€ 0.7ì´ˆ íŒ¨ë”© + ì˜¤ë²„ë© (ì ì ˆí•œ ì»¨í…ìŠ¤íŠ¸)
        end_padding_seconds = 0.7  # 1ì´ˆ â†’ 0.7ì´ˆë¡œ ê°ì†Œ
        max_end_time = len(audio_array) / 16000.0
        padded_end_time = min(max_end_time, chunk_end_time + end_padding_seconds)
        actual_end_padding = padded_end_time - chunk_end_time
        
        logger.info(f"   â© ë íŒ¨ë”©+ì˜¤ë²„ë©: {chunk_end_time:.2f}s â†’ {padded_end_time:.2f}s (íŒ¨ë”©: {actual_end_padding:.2f}s)")
        
        # ìƒ˜í”Œ ì¸ë±ìŠ¤ (íŒ¨ë”© í¬í•¨)
        chunk_start_sample = int(padded_start_time * 16000)
        chunk_end_sample = int(padded_end_time * 16000)
        
        # ë²”ìœ„ ì²´í¬
        chunk_end_sample = min(chunk_end_sample, len(audio_array))
        actual_end_time = chunk_end_sample / 16000.0
        
        logger.info(f"   ğŸ”¢ ìƒ˜í”Œ ì¸ë±ìŠ¤: {chunk_start_sample} ~ {chunk_end_sample}")
        logger.info(f"   â±ï¸ ìµœì¢… ì²­í¬ ì‹œê°„: {padded_start_time:.2f}s~{actual_end_time:.2f}s")
        
        # ì˜¤ë””ì˜¤ ì¶”ì¶œ (íŒ¨ë”© í¬í•¨)
        chunk_audio = audio_array[chunk_start_sample:chunk_end_sample]
        final_duration = len(chunk_audio) / 16000.0
        
        logger.info(f"   ğŸµ ì¶”ì¶œëœ ì˜¤ë””ì˜¤: {len(chunk_audio)}ìƒ˜í”Œ ({final_duration:.2f}ì´ˆ)")
        
        # ì²­í¬ ë‚´ ë¬´ìŒ êµ¬ê°„ ë¶„ì„
        if len(segments) > 1:
            logger.info(f"   ğŸ”‡ ì²­í¬ ë‚´ ë¬´ìŒ êµ¬ê°„:")
            for i in range(len(segments) - 1):
                silence_start = segments[i]['end_time']
                silence_end = segments[i + 1]['start_time']
                silence_duration = silence_end - silence_start
                logger.info(f"      ë¬´ìŒ {i+1}: {silence_start:.2f}s~{silence_end:.2f}s (ê¸¸ì´: {silence_duration:.2f}s)")
        
        # ì•ë¶€ë¶„ ì†ì‹¤ ìœ„í—˜ ì²´í¬
        if chunk_start_time > 0.5:  # ì²« ë²ˆì§¸ ìŒì„±ì´ 0.5ì´ˆ ì´í›„ì— ì‹œì‘ë˜ë©´ ê²½ê³ 
            logger.warning(f"âš ï¸ ì•ë¶€ë¶„ ì†ì‹¤ ìœ„í—˜! ì²« ë²ˆì§¸ ìŒì„±ì´ {chunk_start_time:.2f}ì´ˆì— ì‹œì‘")
            if not is_first_chunk:
                logger.warning(f"   ì´ ì²­í¬ëŠ” ì²« ë²ˆì§¸ê°€ ì•„ë‹ˆë¯€ë¡œ {padded_start_time:.2f}ì´ˆë¶€í„° ì‹œì‘")
        
        return {
            'audio': chunk_audio,
            'start_time': padded_start_time,
            'end_time': actual_end_time,
            'original_start_time': chunk_start_time,
            'original_end_time': chunk_end_time,
            'segments': segments,
            'duration': final_duration,
            'start_padding': actual_start_padding,
            'end_padding': actual_end_padding,
            'overlap_start': actual_start_padding,  # ì˜¤ë²„ë© ì •ë³´ ì¶”ê°€
            'overlap_end': actual_end_padding       # ì˜¤ë²„ë© ì •ë³´ ì¶”ê°€
        }
    
    def _extract_text_from_result(self, result) -> str:
        """NeMo ê²°ê³¼ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¤ì–‘í•œ í˜•íƒœ ì§€ì›, JSON ì§ë ¬í™” ì•ˆì „)"""
        try:
            # None ì²´í¬
            if result is None:
                return ""
            
            # numpy.ndarray ì²˜ë¦¬ - ë” ì•ˆì „í•œ ë°©ì‹
            if hasattr(result, '__array__') and hasattr(result, 'dtype'):
                try:
                    # ë°°ì—´ì„ Python ê°ì²´ë¡œ ì•ˆì „í•˜ê²Œ ë³€í™˜
                    if hasattr(result, 'tolist'):
                        converted = result.tolist()
                        return self._extract_text_from_result(converted)
                    elif hasattr(result, 'item') and result.ndim == 0:
                        # ìŠ¤ì¹¼ë¼ ë°°ì—´
                        converted = result.item()
                        return str(converted).strip()
                    else:
                        # ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ë¬¸ìì—´ ë³€í™˜
                        converted = str(result)
                        return converted.strip()
                except Exception as e:
                    logger.warning(f"âš ï¸ numpy ë°°ì—´ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    return ""
            
            # ë¬¸ìì—´ì¸ ê²½ìš°
            if isinstance(result, str):
                return result.strip()
            
            # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            elif isinstance(result, list):
                if len(result) == 0:
                    return ""
                
                # ì²« ë²ˆì§¸ ìš”ì†Œê°€ ë¬¸ìì—´ì¸ ê²½ìš°
                first_item = result[0]
                
                if isinstance(first_item, str):
                    return first_item.strip()
                
                # ì²« ë²ˆì§¸ ìš”ì†Œê°€ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
                elif isinstance(first_item, dict):
                    if 'text' in first_item:
                        return str(first_item['text']).strip()
                    elif 'transcription' in first_item:
                        return str(first_item['transcription']).strip()
                
                # ì²« ë²ˆì§¸ ìš”ì†Œê°€ ê°ì²´ì¸ ê²½ìš°
                elif hasattr(first_item, 'text'):
                    return str(first_item.text).strip()
                
                # numpy ë°°ì—´ì´ë‚˜ ì§ë ¬í™” ë¶ˆê°€ëŠ¥í•œ ê°ì²´ì¸ ê²½ìš° ì¬ê·€ ì²˜ë¦¬
                elif hasattr(first_item, '__array__'):
                    return self._extract_text_from_result(first_item)
                elif not self._is_json_serializable(first_item):
                    try:
                        result_str = str(first_item).strip()
                        return result_str
                    except:
                        return ""
                
                # ê¸°íƒ€ ê²½ìš° ë¬¸ìì—´ ë³€í™˜ ì‹œë„
                else:
                    try:
                        result_str = str(first_item).strip()
                        return result_str
                    except:
                        return ""
            
            # ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš°
            elif isinstance(result, dict):
                if 'text' in result:
                    return str(result['text']).strip()
                elif 'transcription' in result:
                    return str(result['transcription']).strip()
                elif 'result' in result:
                    return self._extract_text_from_result(result['result'])
            
            # íŠœí”Œì¸ ê²½ìš°
            elif isinstance(result, tuple):
                if len(result) > 0:
                    return self._extract_text_from_result(result[0])
                return ""
            
            # ê°ì²´ì¸ ê²½ìš° (text ì†ì„± í™•ì¸)
            elif hasattr(result, 'text'):
                return str(result.text).strip()
            
            # ì§ë ¬í™” ê°€ëŠ¥ì„± ì²´í¬
            elif not self._is_json_serializable(result):
                try:
                    result_str = str(result).strip()
                    return result_str
                except:
                    return ""
            
            # ê¸°íƒ€ ê²½ìš° ë¬¸ìì—´ ë³€í™˜ ì‹œë„
            else:
                try:
                    result_str = str(result).strip()
                    return result_str
                except:
                    return ""
                    
        except Exception as e:
            logger.error(f"âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def _is_json_serializable(self, obj) -> bool:
        """ê°ì²´ê°€ JSON ì§ë ¬í™” ê°€ëŠ¥í•œì§€ í™•ì¸"""
        try:
            import json
            json.dumps(obj)
            return True
        except (TypeError, ValueError):
            return False

    def _preprocess_audio(self, audio_data: np.ndarray) -> np.ndarray:
        """ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì²˜ë¦¬ (ì •ê·œí™”, ë…¸ì´ì¦ˆ ê°ì†Œ, í•„í„°ë§)"""
        try:
            # 1. ê¸°ë³¸ ì •ê·œí™”
            if np.max(np.abs(audio_data)) > 0:
                # RMS ê¸°ë°˜ ì •ê·œí™” (ì ì ˆí•œ ë³¼ë¥¨ ì¡°ì •)
                rms = np.sqrt(np.mean(audio_data ** 2))
                target_rms = 0.15  # ëª©í‘œ RMS ë ˆë²¨ (0.2 â†’ 0.15ë¡œ ê°ì†Œ)
                if rms > 0:
                    normalization_factor = target_rms / rms
                    audio_data = audio_data * normalization_factor
                    logger.debug(f"ğŸ”§ RMS ì •ê·œí™”: {rms:.4f} â†’ {target_rms:.4f} (factor: {normalization_factor:.4f})")
                
                # í´ë¦¬í•‘ ë°©ì§€
                max_val = np.max(np.abs(audio_data))
                if max_val > 0.9:  # 0.95 â†’ 0.9ë¡œ ê°ì†Œ
                    audio_data = audio_data * (0.9 / max_val)
                    logger.debug(f"ğŸ”§ í´ë¦¬í•‘ ë°©ì§€: ìµœëŒ€ê°’ {max_val:.4f} â†’ 0.9")
            
            # 2. ê³ ì£¼íŒŒ ë° ì €ì£¼íŒŒ í•„í„°ë§ (optional, ë” ë³´ìˆ˜ì ìœ¼ë¡œ ì¡°ì •)
            try:
                from scipy import signal
                
                # 16kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸ ê°€ì •
                fs = 16000
                
                # ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆ ì œê±° (7.5kHz ì´ìƒ ì°¨ë‹¨ â†’ 7kHzë¡œ ë‚®ì¶¤)
                nyquist = fs / 2
                high_cutoff = 7000  # 7kHz
                sos_high = signal.butter(3, high_cutoff / nyquist, btype='low', output='sos')
                audio_data = signal.sosfilt(sos_high, audio_data)
                
                # ì €ì£¼íŒŒ ë…¸ì´ì¦ˆ ì œê±° (100Hz ì´í•˜ ì°¨ë‹¨ â†’ 80Hzë¡œ ë‚®ì¶¤)
                low_cutoff = 80  # 80Hz
                sos_low = signal.butter(2, low_cutoff / nyquist, btype='high', output='sos')
                audio_data = signal.sosfilt(sos_low, audio_data)
                
                logger.debug(f"ğŸ”§ ì£¼íŒŒìˆ˜ í•„í„°ë§ ì ìš©: {low_cutoff}Hz~{high_cutoff}Hz")
                
            except ImportError:
                logger.debug("ğŸ“ scipy ì—†ìŒ, ì£¼íŒŒìˆ˜ í•„í„°ë§ ìŠ¤í‚µ")
            except Exception as e:
                logger.warning(f"âš ï¸ ì£¼íŒŒìˆ˜ í•„í„°ë§ ì‹¤íŒ¨: {e}")
            
            # 3. ë™ì  ë²”ìœ„ ì••ì¶• (ì†Œë¦¬ê°€ ì‘ì€ ë¶€ë¶„ì„ ì ì ˆíˆ ì¦í­)
            try:
                # ì»´í”„ë ˆì„œ íš¨ê³¼ (ë³´ìˆ˜ì  ì ìš©)
                threshold = 0.15  # ì„ê³„ê°’ (0.1 â†’ 0.15ë¡œ ì¦ê°€)
                ratio = 1.8      # ì••ì¶•ë¹„ (2.0 â†’ 1.8ë¡œ ê°ì†Œ, ë” ìì—°ìŠ¤ëŸ½ê²Œ)
                
                # ì‹ í˜¸ì˜ ì ˆëŒ“ê°’ ê³„ì‚°
                abs_audio = np.abs(audio_data)
                
                # ì„ê³„ê°’ ì´ìƒì—ì„œë§Œ ì••ì¶• ì ìš©
                compressed_mask = abs_audio > threshold
                if np.any(compressed_mask):
                    # ì••ì¶• ì ìš©
                    compressed_gain = threshold + (abs_audio[compressed_mask] - threshold) / ratio
                    compression_factor = compressed_gain / abs_audio[compressed_mask]
                    
                    # ì›ë³¸ ì‹ í˜¸ì— ì••ì¶• ì ìš© (ë¶€í˜¸ ìœ ì§€)
                    audio_data[compressed_mask] = audio_data[compressed_mask] * compression_factor
                    
                    logger.debug(f"ğŸ”§ ë™ì  ë²”ìœ„ ì••ì¶• ì ìš©: ì„ê³„ê°’ {threshold}, ë¹„ìœ¨ 1:{ratio}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ ë™ì  ë²”ìœ„ ì••ì¶• ì‹¤íŒ¨: {e}")
            
            # 4. ìµœì¢… ì •ê·œí™” (ë¶€ë“œëŸ½ê²Œ)
            max_val = np.max(np.abs(audio_data))
            if max_val > 0.9:
                audio_data = audio_data * (0.9 / max_val)
                logger.debug(f"ğŸ”§ ìµœì¢… ì •ê·œí™”: {max_val:.4f} â†’ 0.9")
            
            return audio_data.astype(np.float32)
            
        except Exception as e:
            logger.warning(f"âš ï¸ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return audio_data.astype(np.float32)
    
    def _calculate_text_confidence(self, text: str) -> float:
        """í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚° (ë‹¨ì–´ ëˆ„ë½ ë°©ì§€ë¥¼ ìœ„í•œ íœ´ë¦¬ìŠ¤í‹±)"""
        if not text or not text.strip():
            return 0.0
        
        try:
            # ê¸°ë³¸ ì ìˆ˜
            base_score = 0.5
            
            # 1. í…ìŠ¤íŠ¸ ê¸¸ì´ ì ìˆ˜ (ì ì ˆí•œ ê¸¸ì´ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
            text_length = len(text.strip())
            if text_length > 5:
                length_score = min(0.3, text_length / 100.0)  # ìµœëŒ€ 0.3ì 
            else:
                length_score = text_length * 0.02  # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ë‚®ì€ ì ìˆ˜
            
            # 2. í•œêµ­ì–´ ë¹„ìœ¨ ì ìˆ˜
            korean_chars = sum(1 for char in text if '\uac00' <= char <= '\ud7af')
            if len(text) > 0:
                korean_ratio = korean_chars / len(text)
                korean_score = korean_ratio * 0.2  # ìµœëŒ€ 0.2ì 
            else:
                korean_score = 0.0
            
            # 3. ì™„ì„±ë„ ì ìˆ˜ (ë¬¸ì¥ ë í‘œì‹œ, ë¬¸ë²•ì  ì™„ì„±ë„)
            completion_score = 0.0
            if text.endswith(('.', '!', '?', 'ë‹¤', 'ìš”', 'ìŠµë‹ˆë‹¤')):
                completion_score += 0.1
            
            # ë‹¨ì–´ ìˆ˜ê°€ ì ì ˆí•œì§€ í™•ì¸
            words = text.split()
            if len(words) >= 2:
                completion_score += 0.05
            
            # 4. ë°˜ë³µ íŒ¨í„´ ê°ì§€ (ë¶€ì •ì  ìš”ì†Œ)
            repeated_chars = 0
            for char in set(text):
                count = text.count(char)
                if count > len(text) * 0.3:  # í•œ ê¸€ìê°€ 30% ì´ìƒ ë°˜ë³µ
                    repeated_chars += 1
            
            repetition_penalty = min(0.2, repeated_chars * 0.05)
            
            # 5. íŠ¹ìˆ˜ë¬¸ì ë¹„ìœ¨ (ë„ˆë¬´ ë§ìœ¼ë©´ ê°ì )
            special_chars = sum(1 for char in text if not char.isalnum() and char not in ' .,!?')
            if len(text) > 0:
                special_ratio = special_chars / len(text)
                special_penalty = min(0.1, special_ratio * 0.5)
            else:
                special_penalty = 0.0
            
            # ìµœì¢… ì‹ ë¢°ë„ ê³„ì‚°
            confidence = base_score + length_score + korean_score + completion_score - repetition_penalty - special_penalty
            
            # 0.0 ~ 1.0 ë²”ìœ„ë¡œ ì œí•œ
            confidence = max(0.0, min(1.0, confidence))
            
            return confidence
            
        except Exception as e:
            logger.warning(f"âš ï¸ í…ìŠ¤íŠ¸ ì‹ ë¢°ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.5  # ê¸°ë³¸ê°’
    
    def _calculate_confidence(self, text: str, duration: float) -> float:
        """ê°„ë‹¨í•œ ì‹ ë¢°ë„ ê³„ì‚°"""
        if not text.strip():
            return 0.0
        
        # ê¸°ë³¸ ì‹ ë¢°ë„
        base_confidence = 0.85
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ì¡°ì •
        text_length = len(text.strip())
        if text_length < 3:
            base_confidence -= 0.2
        elif text_length > 50:
            base_confidence += 0.1
        
        # ì§€ì† ì‹œê°„ ê¸°ë°˜ ì¡°ì •
        if duration < 1.0:
            base_confidence -= 0.1
        elif duration > 10.0:
            base_confidence += 0.05
        
        return min(0.99, max(0.1, base_confidence))
    
    def _create_segments(self, text: str, duration: float) -> List[Dict[str, Any]]:
        """ê¸°ë³¸ì ì¸ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„± (NeMoëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•ŠìŒ)"""
        if not text.strip():
            return []
        
        # ê°„ë‹¨í•œ ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
        confidence = self._calculate_confidence(text, duration)
        
        return [{
            "id": 0,
            "text": text.strip(),
            "start": 0.0,
            "end": duration,
            "confidence": confidence,
            "words": []  # NeMoì—ì„œ ë‹¨ì–´ ë ˆë²¨ íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” ë³„ë„ ì²˜ë¦¬ í•„ìš”
        }]
    
    def is_healthy(self) -> bool:
        """NeMo ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
        return self.is_initialized and self.model is not None
    
    def get_model_info(self) -> Dict[str, Any]:
        """NeMo ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        info = {
            "model_type": "nemo",
            "model_name": self.model_name,
            "device": self.device,
            "is_initialized": self.is_initialized,
            "is_healthy": self.is_healthy(),
            "sample_rate": self.sample_rate,
            "gpu_optimized": torch.cuda.is_available() and self.device == "cuda",
            "nemo_available": NEMO_AVAILABLE
        }
        
        # ëª¨ë¸ì´ ë¡œë“œëœ ê²½ìš° ì¶”ê°€ ì •ë³´
        if self.model is not None:
            try:
                # NeMo ëª¨ë¸ì˜ ì„¤ì • ì •ë³´ ì¶”ê°€
                if hasattr(self.model, 'cfg'):
                    info["model_config"] = {
                        "sample_rate": getattr(self.model.cfg, 'sample_rate', self.sample_rate),
                        "n_mels": getattr(self.model.cfg.preprocessor, 'n_mels', 'unknown'),
                        "vocab_size": len(getattr(self.model, 'decoder', {}).vocabulary) if hasattr(self.model, 'decoder') else 'unknown'
                    }
            except Exception as e:
                logger.warning(f"âš ï¸ ëª¨ë¸ ì„¤ì • ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        
        return info 