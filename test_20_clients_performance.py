#!/usr/bin/env python3
"""
20ê°œ ë™ì‹œ í´ë¼ì´ì–¸íŠ¸ STT ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
í˜„ì‹¤ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ ê¸¸ì´ì™€ ìš°ì„ ìˆœìœ„ í…ŒìŠ¤íŠ¸
"""

import asyncio
import aiohttp
import base64
import json
import time
import numpy as np
from typing import Dict, List, Any
import threading
from concurrent.futures import ThreadPoolExecutor
import psutil
import statistics

# ì„œë²„ ì„¤ì •
SERVER_URL = "http://localhost:8001"
NUM_CLIENTS = 20
TEST_DURATION = 60  # 60ì´ˆê°„ í…ŒìŠ¤íŠ¸

class PerformanceMetrics:
    """ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ í´ë˜ìŠ¤"""
    def __init__(self):
        self.request_times = []
        self.processing_times = []
        self.wait_times = []
        self.rtf_values = []
        self.success_count = 0
        self.failure_count = 0
        self.total_requests = 0
        self.start_time = None
        self.end_time = None
        self.lock = threading.Lock()
    
    def add_result(self, success: bool, request_time: float = 0, 
                   processing_time: float = 0, wait_time: float = 0, rtf: float = 0):
        with self.lock:
            self.total_requests += 1
            if success:
                self.success_count += 1
                self.request_times.append(request_time)
                self.processing_times.append(processing_time)
                self.wait_times.append(wait_time)
                self.rtf_values.append(rtf)
            else:
                self.failure_count += 1
    
    def get_summary(self) -> Dict[str, Any]:
        with self.lock:
            duration = (self.end_time - self.start_time) if self.start_time and self.end_time else 0
            
            return {
                "duration_seconds": duration,
                "total_requests": self.total_requests,
                "successful_requests": self.success_count,
                "failed_requests": self.failure_count,
                "success_rate": (self.success_count / self.total_requests * 100) if self.total_requests > 0 else 0,
                "throughput_rps": self.success_count / duration if duration > 0 else 0,
                "avg_request_time": statistics.mean(self.request_times) if self.request_times else 0,
                "median_request_time": statistics.median(self.request_times) if self.request_times else 0,
                "p95_request_time": np.percentile(self.request_times, 95) if self.request_times else 0,
                "p99_request_time": np.percentile(self.request_times, 99) if self.request_times else 0,
                "avg_processing_time": statistics.mean(self.processing_times) if self.processing_times else 0,
                "avg_wait_time": statistics.mean(self.wait_times) if self.wait_times else 0,
                "avg_rtf": statistics.mean(self.rtf_values) if self.rtf_values else 0,
                "median_rtf": statistics.median(self.rtf_values) if self.rtf_values else 0
            }

def create_test_audio(duration_seconds: float = 1.0, frequency: int = 440) -> str:
    """ë‹¤ì–‘í•œ ê¸¸ì´ì˜ í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„±"""
    sample_rate = 16000
    samples = int(sample_rate * duration_seconds)
    
    # ì‚¬ì¸íŒŒ ìƒì„±
    t = np.linspace(0, duration_seconds, samples, False)
    audio = np.sin(2 * np.pi * frequency * t)
    
    # 16ë¹„íŠ¸ PCMìœ¼ë¡œ ë³€í™˜
    audio_int16 = (audio * 32767).astype(np.int16)
    audio_bytes = audio_int16.tobytes()
    
    return base64.b64encode(audio_bytes).decode('utf-8')

async def single_client_test(session: aiohttp.ClientSession, 
                           client_id: int, 
                           metrics: PerformanceMetrics,
                           test_configs: List[Dict]) -> None:
    """ë‹¨ì¼ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    for i, config in enumerate(test_configs):
        request_start = time.time()
        
        try:
            # ìš”ì²­ ì œì¶œ
            queue_request = {
                "audio_data": config["audio_data"],
                "language": "ko",
                "client_id": f"client_{client_id:02d}",
                "priority": config["priority"]
            }
            
            async with session.post(f"{SERVER_URL}/queue/transcribe", 
                                  json=queue_request) as response:
                if response.status == 200:
                    queue_response = await response.json()
                    request_id = queue_response["request_id"]
                    
                    # ê²°ê³¼ ëŒ€ê¸°
                    max_wait = 30  # 30ì´ˆ ìµœëŒ€ ëŒ€ê¸°
                    wait_start = time.time()
                    
                    while time.time() - wait_start < max_wait:
                        try:
                            async with session.get(f"{SERVER_URL}/queue/result/{request_id}") as result_response:
                                if result_response.status == 200:
                                    result = await result_response.json()
                                    request_end = time.time()
                                    
                                    request_time = request_end - request_start
                                    wait_time = time.time() - wait_start
                                    processing_time = result.get("processing_time", 0)
                                    rtf = result.get("rtf", 0)
                                    
                                    metrics.add_result(
                                        success=True,
                                        request_time=request_time,
                                        processing_time=processing_time,
                                        wait_time=wait_time,
                                        rtf=rtf
                                    )
                                    
                                    print(f"âœ… í´ë¼ì´ì–¸íŠ¸ {client_id:02d}-{i+1:02d}: "
                                          f"ì´ì‹œê°„={request_time:.3f}s, "
                                          f"ì²˜ë¦¬={processing_time:.3f}s, "
                                          f"RTF={rtf:.3f}, "
                                          f"ìš°ì„ ìˆœìœ„={config['priority']}")
                                    break
                                    
                        except Exception as e:
                            await asyncio.sleep(0.1)
                    else:
                        # íƒ€ì„ì•„ì›ƒ
                        metrics.add_result(success=False)
                        print(f"â° í´ë¼ì´ì–¸íŠ¸ {client_id:02d}-{i+1:02d}: íƒ€ì„ì•„ì›ƒ")
                        
                else:
                    metrics.add_result(success=False)
                    print(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id:02d}-{i+1:02d}: ìš”ì²­ ì‹¤íŒ¨ ({response.status})")
                    
        except Exception as e:
            metrics.add_result(success=False)
            print(f"âŒ í´ë¼ì´ì–¸íŠ¸ {client_id:02d}-{i+1:02d}: ì˜ˆì™¸ - {e}")
        
        # í´ë¼ì´ì–¸íŠ¸ ê°„ ìš”ì²­ ê°„ê²© (í˜„ì‹¤ì ì¸ ì‹œë®¬ë ˆì´ì…˜)
        await asyncio.sleep(np.random.uniform(0.1, 0.5))

def monitor_system_resources(duration: int, interval: float = 1.0) -> Dict[str, List]:
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
    cpu_usage = []
    memory_usage = []
    
    start_time = time.time()
    while time.time() - start_time < duration:
        cpu_usage.append(psutil.cpu_percent())
        memory_usage.append(psutil.virtual_memory().percent)
        time.sleep(interval)
    
    return {
        "cpu_usage": cpu_usage,
        "memory_usage": memory_usage,
        "avg_cpu": statistics.mean(cpu_usage),
        "max_cpu": max(cpu_usage),
        "avg_memory": statistics.mean(memory_usage),
        "max_memory": max(memory_usage)
    }

async def test_queue_stats_monitoring(session: aiohttp.ClientSession, duration: int):
    """í í†µê³„ ëª¨ë‹ˆí„°ë§"""
    stats_history = []
    start_time = time.time()
    
    while time.time() - start_time < duration:
        try:
            async with session.get(f"{SERVER_URL}/queue/stats") as response:
                if response.status == 200:
                    stats = await response.json()
                    stats["timestamp"] = time.time() - start_time
                    stats_history.append(stats)
        except Exception as e:
            pass
        
        await asyncio.sleep(2)  # 2ì´ˆë§ˆë‹¤ í†µê³„ ìˆ˜ì§‘
    
    return stats_history

async def run_20_client_performance_test():
    """20ê°œ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ 20ê°œ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ STT ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì • ìƒì„± (ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤)
    test_scenarios = []
    audio_durations = [0.5, 1.0, 2.0, 3.0, 5.0]  # ë‹¤ì–‘í•œ ì˜¤ë””ì˜¤ ê¸¸ì´
    priorities = ["high", "medium", "low"]
    frequencies = [220, 440, 880, 1320]  # ë‹¤ì–‘í•œ ì£¼íŒŒìˆ˜
    
    for i in range(5):  # í´ë¼ì´ì–¸íŠ¸ë‹¹ 5ê°œ ìš”ì²­
        duration = np.random.choice(audio_durations)
        priority = np.random.choice(priorities)
        frequency = np.random.choice(frequencies)
        
        test_scenarios.append({
            "audio_data": create_test_audio(duration, frequency),
            "priority": priority,
            "duration": duration,
            "frequency": frequency
        })
    
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:")
    print(f"   í´ë¼ì´ì–¸íŠ¸ ìˆ˜: {NUM_CLIENTS}ê°œ")
    print(f"   í´ë¼ì´ì–¸íŠ¸ë‹¹ ìš”ì²­: {len(test_scenarios)}ê°œ")
    print(f"   ì´ ì˜ˆìƒ ìš”ì²­: {NUM_CLIENTS * len(test_scenarios)}ê°œ")
    print(f"   ì˜¤ë””ì˜¤ ê¸¸ì´: {min(audio_durations)}-{max(audio_durations)}ì´ˆ")
    print(f"   ìš°ì„ ìˆœìœ„: {', '.join(priorities)}")
    
    # ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ê¸°
    metrics = PerformanceMetrics()
    
    # 1. ì„œë²„ ìƒíƒœ í™•ì¸
    print("\n1ï¸âƒ£ ì„œë²„ ìƒíƒœ í™•ì¸:")
    connector = aiohttp.TCPConnector(limit=50, limit_per_host=30)
    timeout = aiohttp.ClientTimeout(total=60)
    
    async with aiohttp.ClientSession(connector=connector, timeout=timeout) as session:
        try:
            async with session.get(f"{SERVER_URL}/health") as response:
                if response.status == 200:
                    health = await response.json()
                    print(f"   âœ… ì„œë²„: {health['status']}")
                    print(f"   ğŸ”¥ GPU: {health['gpu_name']}")
                    print(f"   ğŸš€ cuDNN: {health['cudnn_enabled']}")
                else:
                    print("   âŒ ì„œë²„ ìƒíƒœ ë¶ˆëŸ‰")
                    return
        except Exception as e:
            print(f"   âŒ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            return
        
        # 2. ì´ˆê¸° í ìƒíƒœ í™•ì¸
        print("\n2ï¸âƒ£ ì´ˆê¸° í ìƒíƒœ:")
        try:
            async with session.get(f"{SERVER_URL}/queue/stats") as response:
                stats = await response.json()
                print(f"   ëŒ€ê¸°: {stats['queued_requests']}, "
                      f"ì²˜ë¦¬ì¤‘: {stats['processing_requests']}, "
                      f"ì™„ë£Œ: {stats['completed_requests']}, "
                      f"ì‹¤íŒ¨: {stats['failed_requests']}")
                print(f"   ìµœëŒ€ ë™ì‹œì²˜ë¦¬: {stats['max_concurrent']}, "
                      f"í ìš©ëŸ‰: {stats['queue_capacity']}")
        except Exception as e:
            print(f"   âŒ í ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # 3. ë™ì‹œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        print(f"\n3ï¸âƒ£ {NUM_CLIENTS}ê°œ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰:")
        print("   (ì‹¤ì‹œê°„ ê²°ê³¼ í‘œì‹œ)")
        
        # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        estimated_duration = len(test_scenarios) * 2  # ì˜ˆìƒ í…ŒìŠ¤íŠ¸ ì‹œê°„
        resource_future = asyncio.get_event_loop().run_in_executor(
            ThreadPoolExecutor(), 
            monitor_system_resources, 
            estimated_duration + 10
        )
        
        # í í†µê³„ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        stats_future = asyncio.create_task(
            test_queue_stats_monitoring(session, estimated_duration + 10)
        )
        
        # í…ŒìŠ¤íŠ¸ ì‹œì‘
        metrics.start_time = time.time()
        
        # 20ê°œ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ ì‹¤í–‰
        client_tasks = []
        for client_id in range(NUM_CLIENTS):
            task = asyncio.create_task(
                single_client_test(session, client_id, metrics, test_scenarios)
            )
            client_tasks.append(task)
        
        # ëª¨ë“  í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ ëŒ€ê¸°
        await asyncio.gather(*client_tasks)
        
        metrics.end_time = time.time()
        
        # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
        try:
            resource_stats = await resource_future
        except:
            resource_stats = {"avg_cpu": 0, "max_cpu": 0, "avg_memory": 0, "max_memory": 0}
        
        # í í†µê³„ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
        stats_future.cancel()
        try:
            queue_stats_history = await stats_future
        except:
            queue_stats_history = []
        
        # 4. ìµœì¢… í ìƒíƒœ í™•ì¸
        print("\n4ï¸âƒ£ ìµœì¢… í ìƒíƒœ:")
        try:
            async with session.get(f"{SERVER_URL}/queue/stats") as response:
                final_stats = await response.json()
                print(f"   ğŸ“Š ì´ ìš”ì²­: {final_stats['total_requests']}ê°œ")
                print(f"   âœ… ì™„ë£Œ: {final_stats['completed_requests']}ê°œ")
                print(f"   âŒ ì‹¤íŒ¨: {final_stats['failed_requests']}ê°œ")
                print(f"   â³ ëŒ€ê¸°ì¤‘: {final_stats['queued_requests']}ê°œ")
                print(f"   ğŸ”„ ì²˜ë¦¬ì¤‘: {final_stats['processing_requests']}ê°œ")
                print(f"   âš¡ ì²˜ë¦¬ëŸ‰: {final_stats['current_throughput']:.2f} ìš”ì²­/ë¶„")
        except Exception as e:
            print(f"   âŒ ìµœì¢… í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    # 5. ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼
    print("\n5ï¸âƒ£ ì„±ëŠ¥ ë¶„ì„ ê²°ê³¼:")
    summary = metrics.get_summary()
    
    print("=" * 60)
    print("ğŸ“Š ì „ì²´ ì„±ëŠ¥ ìš”ì•½:")
    print(f"   ğŸ• í…ŒìŠ¤íŠ¸ ì‹œê°„: {summary['duration_seconds']:.1f}ì´ˆ")
    print(f"   ğŸ“ ì´ ìš”ì²­ìˆ˜: {summary['total_requests']}ê°œ")
    print(f"   âœ… ì„±ê³µ: {summary['successful_requests']}ê°œ ({summary['success_rate']:.1f}%)")
    print(f"   âŒ ì‹¤íŒ¨: {summary['failed_requests']}ê°œ")
    print(f"   âš¡ ì²˜ë¦¬ëŸ‰: {summary['throughput_rps']:.2f} ìš”ì²­/ì´ˆ")
    
    print("\nâ±ï¸ ì‘ë‹µ ì‹œê°„ ë¶„ì„:")
    print(f"   í‰ê· : {summary['avg_request_time']:.3f}ì´ˆ")
    print(f"   ì¤‘ê°„ê°’: {summary['median_request_time']:.3f}ì´ˆ")
    print(f"   95%: {summary['p95_request_time']:.3f}ì´ˆ")
    print(f"   99%: {summary['p99_request_time']:.3f}ì´ˆ")
    
    print("\nğŸ”„ ì²˜ë¦¬ ì„±ëŠ¥:")
    print(f"   í‰ê·  ì²˜ë¦¬ì‹œê°„: {summary['avg_processing_time']:.3f}ì´ˆ")
    print(f"   í‰ê·  ëŒ€ê¸°ì‹œê°„: {summary['avg_wait_time']:.3f}ì´ˆ")
    print(f"   í‰ê·  RTF: {summary['avg_rtf']:.3f}x")
    print(f"   ì¤‘ê°„ê°’ RTF: {summary['median_rtf']:.3f}x")
    
    print("\nğŸ’» ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤:")
    print(f"   í‰ê·  CPU: {resource_stats['avg_cpu']:.1f}%")
    print(f"   ìµœëŒ€ CPU: {resource_stats['max_cpu']:.1f}%")
    print(f"   í‰ê·  ë©”ëª¨ë¦¬: {resource_stats['avg_memory']:.1f}%")
    print(f"   ìµœëŒ€ ë©”ëª¨ë¦¬: {resource_stats['max_memory']:.1f}%")
    
    # 6. ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€
    print("\nğŸ† ì„±ëŠ¥ ë“±ê¸‰ í‰ê°€:")
    
    # RTF ê¸°ì¤€ í‰ê°€
    rtf_grade = "ğŸ”´ D"
    if summary['avg_rtf'] < 0.05:
        rtf_grade = "ğŸŸ¢ S+"
    elif summary['avg_rtf'] < 0.1:
        rtf_grade = "ğŸŸ¢ S"
    elif summary['avg_rtf'] < 0.2:
        rtf_grade = "ğŸŸ¡ A"
    elif summary['avg_rtf'] < 0.5:
        rtf_grade = "ğŸŸ  B"
    elif summary['avg_rtf'] < 1.0:
        rtf_grade = "ğŸ”´ C"
    
    # ì„±ê³µë¥  ê¸°ì¤€ í‰ê°€
    success_grade = "ğŸ”´ D"
    if summary['success_rate'] >= 99:
        success_grade = "ğŸŸ¢ S+"
    elif summary['success_rate'] >= 95:
        success_grade = "ğŸŸ¢ S"
    elif summary['success_rate'] >= 90:
        success_grade = "ğŸŸ¡ A"
    elif summary['success_rate'] >= 80:
        success_grade = "ğŸŸ  B"
    elif summary['success_rate'] >= 70:
        success_grade = "ğŸ”´ C"
    
    # ì²˜ë¦¬ëŸ‰ ê¸°ì¤€ í‰ê°€ (20ê°œ í´ë¼ì´ì–¸íŠ¸ ê¸°ì¤€)
    throughput_grade = "ğŸ”´ D"
    if summary['throughput_rps'] >= 15:
        throughput_grade = "ğŸŸ¢ S+"
    elif summary['throughput_rps'] >= 10:
        throughput_grade = "ğŸŸ¢ S"
    elif summary['throughput_rps'] >= 7:
        throughput_grade = "ğŸŸ¡ A"
    elif summary['throughput_rps'] >= 5:
        throughput_grade = "ğŸŸ  B"
    elif summary['throughput_rps'] >= 3:
        throughput_grade = "ğŸ”´ C"
    
    print(f"   RTF ì„±ëŠ¥: {rtf_grade} (í‰ê·  {summary['avg_rtf']:.3f}x)")
    print(f"   ì•ˆì •ì„±: {success_grade} ({summary['success_rate']:.1f}% ì„±ê³µ)")
    print(f"   ì²˜ë¦¬ëŸ‰: {throughput_grade} ({summary['throughput_rps']:.2f} ìš”ì²­/ì´ˆ)")
    
    print("\n" + "=" * 60)
    print("ğŸ¯ 20ê°œ í´ë¼ì´ì–¸íŠ¸ ë™ì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    return summary

if __name__ == "__main__":
    asyncio.run(run_20_client_performance_test()) 